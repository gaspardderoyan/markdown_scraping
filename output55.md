---
domain: langfuse.com
path: /docs/datasets
url: https://langfuse.com/docs/datasets
---

[Join us in Engineering & DevRel →We're hiring. Join us in Product Eng, Backend Eng, and DevRel →](/careers)

[![Langfuse Logo](https://langfuse.com/langfuse_logo_white.svg)![Langfuse Logo](https://langfuse.com/langfuse_logo.svg)](/)
[DocsDocs](/docs)
[PricingPricing](/pricing)
[ChangelogChangelog](/changelog)
[BlogBlog](/blog)

Demo

[Discord](https://discord.langfuse.com)
[](https://x.com/langfuse)
[GitHub](https://github.com/langfuse/langfuse "GitHub Repository")
[Sign Up](https://cloud.langfuse.com)

*   Docs
    
    [Guides](/guides)
    [FAQ](/faq)
    
*   [Overview](/docs)
    
*   [Interactive Demo](/docs/demo)
    
*   Self-host
    
    *   [Local (docker compose)](/docs/deployment/local)
        
    *   [Self-host (docker)](/docs/deployment/self-host)
        
    
*   Tracing
*   [Introduction](/docs/tracing)
    
*   [Quickstart](/docs/get-started)
    
*   Features
    
    *   [Sessions](/docs/tracing-features/sessions)
        
    *   [Users](/docs/tracing-features/users)
        
    *   [Metadata](/docs/tracing-features/metadata)
        
    *   [Tags](/docs/tracing-features/tags)
        
    *   [Trace URL](/docs/tracing-features/url)
        
    *   [Log Levels](/docs/tracing-features/log-levels)
        
    *   [Sampling](/docs/tracing-features/sampling)
        
    
*   SDKs
    
    *   [Overview](/docs/sdk/overview)
        
    *   Python
        
        *   [Decorators](/docs/sdk/python/decorators)
            
        *   [Example Notebook](/docs/sdk/python/example)
            
        *   [Low-level SDK](/docs/sdk/python/low-level-sdk)
            
        *   [Reference ↗ (opens in a new tab)](https://python.reference.langfuse.com)
            
        
    *   JS/TS
        
        *   [Guide](/docs/sdk/typescript/guide)
            
        *   [Guide (Web)](/docs/sdk/typescript/guide-web)
            
        *   [Example (Vercel AI)](/docs/sdk/typescript/example-vercel-ai)
            
        *   [Reference ↗ (opens in a new tab)](https://js.reference.langfuse.com)
            
        
    
*   Integrations
    
    *   [Overview](/docs/integrations/overview)
        
    *   OpenAI SDK
        
        *   Python
            
            *   [Get Started](/docs/integrations/openai/python/get-started)
                
            *   [Track Errors](/docs/integrations/openai/python/track-errors)
                
            *   [Example Notebook](/docs/integrations/openai/python/examples)
                
            *   [Assistants API](/docs/integrations/openai/python/assistants-api)
                
            *   [Structured Outputs](/docs/integrations/openai/python/structured-outputs)
                
            
        *   JS/TS
            
            *   [Get Started](/docs/integrations/openai/js/get-started)
                
            *   [Example Notebook](/docs/integrations/openai/js/examples)
                
            
        
    *   Langchain
        
        *   [Tracing](/docs/integrations/langchain/tracing)
            
        *   [Example Python](/docs/integrations/langchain/example-python)
            
        *   [Example JS](/docs/integrations/langchain/example-javascript)
            
        *   [Example LangGraph](/docs/integrations/langchain/example-python-langgraph)
            
        *   [Example LangServe](/docs/integrations/langchain/example-python-langserve)
            
        *   [Upgrade Paths](/docs/integrations/langchain/upgrade-paths)
            
        
    *   LlamaIndex
        
        *   [Get Started](/docs/integrations/llama-index/get-started)
            
        *   [Example (Python)](/docs/integrations/llama-index/example-python)
            
        
    *   Haystack
        
        *   [Get Started](/docs/integrations/haystack/get-started)
            
        *   [Example (Python)](/docs/integrations/haystack/example-python)
            
        
    *   LiteLLM
        
        *   [Tracing](/docs/integrations/litellm/tracing)
            
        *   [Example Proxy (Python)](/docs/integrations/litellm/example-proxy-python)
            
        *   [Example Proxy (JS/TS)](/docs/integrations/litellm/example-proxy-js)
            
        
    *   [Vercel AI SDK](/docs/integrations/vercel-ai-sdk)
        
    *   [Dify.AI](/docs/integrations/dify)
        
    *   [Instructor](/docs/integrations/instructor)
        
    *   Mirascope
        
        *   [Tracing](/docs/integrations/mirascope/tracing)
            
        *   [Example Notebook](/docs/integrations/mirascope/example-python)
            
        
    *   [Flowise](/docs/integrations/flowise)
        
    *   [Langflow](/docs/integrations/langflow)
        
    
*   [Query Traces](/docs/query-traces)
    
*   Develop
*   Prompt Management
    
    *   [Get Started](/docs/prompts/get-started)
        
    *   [Example OpenAI Functions](/docs/prompts/example-openai-functions)
        
    *   [Example Langchain (Py)](/docs/prompts/example-langchain)
        
    *   [Example Langchain (JS)](/docs/prompts/example-langchain-js)
        
    
*   [Playground](/docs/playground)
    
*   [Fine-tuning](/docs/fine-tuning)
    
*   Monitor
*   Analytics
    
    *   [Overview](/docs/analytics/overview)
        
    *   [PostHog Integration](/docs/analytics/posthog)
        
    *   [Daily Metrics API](/docs/analytics/daily-metrics-api)
        
    
*   [Model Usage & Cost](/docs/model-usage-and-cost)
    
*   Scores & Evaluation
    
    *   [Overview](/docs/scores/overview)
        
    *   [Annotation in UI](/docs/scores/annotation)
        
    *   [User Feedback](/docs/scores/user-feedback)
        
    *   [Model-based Evaluation](/docs/scores/model-based-evals)
        
    *   [Custom via SDKs/API](/docs/scores/custom)
        
    
*   LLM Security
    
    *   [Overview](/docs/security/overview)
        
    *   [Example Python](/docs/security/example-python)
        
    
*   Test
*   [Experimentation](/docs/experimentation)
    
*   Datasets
    
    *   [Overview](/docs/datasets/overview)
        
    *   [Cookbook](/docs/datasets/python-cookbook)
        
    
*   References
*   [API ↗ (opens in a new tab)](https://api.reference.langfuse.com)
    
*   [Python SDK ↗ (opens in a new tab)](https://python.reference.langfuse.com)
    
*   [JS SDK ↗ (opens in a new tab)](https://js.reference.langfuse.com)
    
*   More
*   [Access Control (RBAC)](/docs/rbac)
    
*   [Data Security & Privacy](/docs/data-security-privacy)
    
*   [Open Source](/docs/open-source)
    
*   [Roadmap](/docs/roadmap)
    
*   [Support ↗ (opens in a new tab)](/support)
    

Light

On This Page

*   [Creating a dataset](#creating-a-dataset)
    
*   [Create new dataset items](#create-new-dataset-items)
    
*   [Run experiment on a dataset](#run-experiment-on-a-dataset)
    
*   [Analyze dataset runs](#analyze-dataset-runs)
    
*   [Conceptually](#conceptually)
    
*   [FAQ](#faq)
    

[Question? Give us feedback → (opens in a new tab)](https://github.com/langfuse/langfuse-docs/issues/new?title=Feedback%20for%20%E2%80%9CDatasets%E2%80%9D&labels=feedback)
[Edit this page on GitHub](https://github.com/langfuse/langfuse-docs/tree/main/pages/docs/datasets/overview.mdx)
Scroll to top

Docs

Datasets

Overview

Datasets
========

Datasets in Langfuse are a collection of inputs (and expected outputs) of an LLM application. They are used to benchmark new releases before deployment to production. Datasets can be incrementally created from new edge cases found in production.

_High-level example workflow of using datasets to continuously improve an LLM application:_

![Datasets](https://langfuse.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdataset-example-workflow.3a16b485.png&w=3840&q=75)

_Introduction to Datasets v2:_

Introduction to Datasets v2

For an end-to-end example, check out the [Datasets Notebook (Python)](/docs/datasets/python-cookbook)
.

Creating a dataset[](#creating-a-dataset)

------------------------------------------

Datasets have a name which is unique within a project.

PythonJS/TSUI

    langfuse.create_dataset(
        name="<dataset_name>",
        # optional description
        description="My first dataset",
        # optional metadata
        metadata={
            "author": "Alice",
            "date": "2022-01-01",
            "type": "benchmark"
        }
    )

_See [low-level SDK](/docs/sdk/python/low-level-sdk)
 docs for details on how to initialize the Python client._

Create new dataset items[](#create-new-dataset-items)

------------------------------------------------------

Individual items can be added to a dataset by providing the input and optionally the expected output.

PythonJS/TSUI

    langfuse.create_dataset_item(
        dataset_name="<dataset_name>",
        # any python object or value, optional
        input={
            "text": "hello world"
        },
        # any python object or value, optional
        expected_output={
            "text": "hello world"
        },
        # metadata, optional
        metadata={
            "model": "llama3",
        }
    )

_See [low-level SDK](/docs/sdk/python/low-level-sdk)
 docs for details on how to initialize the Python client._

**Create items from production data**

UIPythonJS/TS

In the UI, use `+ Add to dataset` on any observation (span, event, generation) of a production trace.

**Edit/archive items**

Archiving items will remove them from future experiment runs.

UIPythonJS/TS

In the UI, you can edit or archive items by clicking on the item in the table.

Run experiment on a dataset[](#run-experiment-on-a-dataset)

------------------------------------------------------------

When running an experiment on a dataset, the application that shall be tested is executed for each item in the dataset. The execution trace is then linked to the dataset item. This allows to compare different runs of the same application on the same dataset. Each experiment is identified by a `run_name`.

Optionally, the output of the application can be evaluated to compare different runs more easily. More details on scores/evals [here](/docs/scores/overview)
. Options:

*   Use any evaluation function and directly add a score while running the experiment. See below for implementation details.
*   Set up [model-based evaluation](/docs/scores/model-based-evals)
     within Langfuse to automatically evaluate the outputs of these runs.

Python (decorator)Python (low-level)JS/TSLangchain (Python)LlamaIndex (Python)

    dataset = langfuse.get_dataset("<dataset_name>")
     
    for item in dataset.items:
        # Make sure your application function is decorated with @observe decorator to automatically link the trace
        with item.observe(
            run_name="<run_name>",
            run_description="My first run",
            run_metadata={"model": "llama3"},
        ) as trace_id:
            # run your @observe() decorated application on the dataset item input
            output = my_llm_application.run(item.input)
     
            # optionally, evaluate the output to compare different runs more easily
            langfuse.score(
                trace_id=trace.id,
                name="<example_eval>",
                # any float value
                value=my_eval_fn(item.input, output, item.expected_output),
                comment="This is a comment",  # optional, useful to add reasoning
            )
     
    # Flush the langfuse client to ensure all data is sent to the server at the end of the experiment run
    langfuse.flush()

_See [low-level SDK](/docs/sdk/python/low-level-sdk)
 docs for details on how to initialize the Python client and see the [Python decorator](/docs/sdk/python/decorators)
 docs on how to use the `@observe` decorator for your main application function._

Analyze dataset runs[](#analyze-dataset-runs)

----------------------------------------------

After each experiment run on a dataset, you can check the aggregated score in the dataset runs table.

![Dataset runs](https://langfuse.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdataset_runs_table.084d74f2.png&w=3840&q=75)

Conceptually[](#conceptually)

------------------------------

FAQ[](#faq)

------------

*   [I have setup Langfuse, but I do not see any traces in the dashboard. How to solve this?](/faq/all/missing-traces)
    

[Experimentation](/docs/experimentation "Experimentation")
[Cookbook](/docs/datasets/python-cookbook "Cookbook")

### Was this page useful?

YesCould be better

### Questions? We're here to help

[GitHub Q&AGitHub](/gh-support)
Chat [Email](/cdn-cgi/l/email-protection#cbb8bebbbba4b9bf8ba7aaa5acadbeb8aee5a8a4a6)
[Talk to sales](/schedule-demo)

### Subscribe to updates

Get updates

Light

* * *

Platform

*   [LLM Tracing](/docs/tracing)
    
*   [Prompt Management](/docs/prompts/get-started)
    
*   [Evaluation](/docs/scores/overview)
    
*   [Manual Annotation](/docs/scores/annotation)
    
*   [Datasets](/docs/datasets/overview)
    
*   [Metrics](/docs/analytics)
    
*   [Playground](/docs/playground)
    

Integrations

*   [Python SDK](/docs/sdk/python)
    
*   [JS/TS SDK](/docs/sdk/typescript/guide)
    
*   [OpenAI SDK](/docs/integrations/openai/get-started)
    
*   [Langchain](/docs/integrations/langchain/tracing)
    
*   [Llama-Index](/docs/integrations/llama-index/get-started)
    
*   [Litellm](/docs/integrations/litellm)
    
*   [Dify](/docs/integrations/dify)
    
*   [Flowise](/docs/integrations/flowise)
    
*   [Langflow](/docs/integrations/langflow)
    
*   [Vercel AI SDK](/docs/sdk/typescript/example-vercel-ai)
    
*   [Instructor](/docs/integrations/instructor)
    
*   [Mirascope](/docs/integrations/mirascope)
    
*   [API](https://api.reference.langfuse.com/)
    

Resources

*   [Documentation](/docs)
    
*   [Interactive Demo](/demo)
    
*   [Video demo (3 min)](/video)
    
*   [Changelog](/changelog)
    
*   [Roadmap](/docs/roadmap)
    
*   [Pricing](/pricing)
    
*   [Enterprise](/enterprise)
    
*   [Self-hosting](/docs/deployment/self-host)
    
*   [Open Source](/docs/open-source)
    
*   [Why Langfuse?](/why)
    
*   [Status](https://status.langfuse.com)
    

About

*   [Blog](/blog)
    
*   [Careers](/careers)
    3
*   [About us](/about)
    
*   [Support](/support)
    
*   [Schedule Demo](/schedule-demo)
    
*   [OSS Friends](/oss-friends)
    

Legal

*   [Security](/security)
    
*   [Imprint](/imprint)
    
*   [Terms](/terms)
    
*   [Privacy](/privacy)
    

© 2022-2024 Langfuse GmbH / Finto Technologies Inc.