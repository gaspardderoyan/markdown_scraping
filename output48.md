---
domain: langfuse.com
path: /docs/integrations/langchain/upgrade-paths
url: https://langfuse.com/docs/integrations/langchain/upgrade-paths
---

[Join us in Engineering & DevRel →We're hiring. Join us in Product Eng, Backend Eng, and DevRel →](/careers)

[![Langfuse Logo](https://langfuse.com/langfuse_logo_white.svg)![Langfuse Logo](https://langfuse.com/langfuse_logo.svg)](/)
[DocsDocs](/docs)
[PricingPricing](/pricing)
[ChangelogChangelog](/changelog)
[BlogBlog](/blog)

Demo

[Discord](https://discord.langfuse.com)
[](https://x.com/langfuse)
[GitHub](https://github.com/langfuse/langfuse "GitHub Repository")
[Sign Up](https://cloud.langfuse.com)

*   Docs
    
    [Guides](/guides)
    [FAQ](/faq)
    
*   [Overview](/docs)
    
*   [Interactive Demo](/docs/demo)
    
*   Self-host
    
    *   [Local (docker compose)](/docs/deployment/local)
        
    *   [Self-host (docker)](/docs/deployment/self-host)
        
    
*   Tracing
*   [Introduction](/docs/tracing)
    
*   [Quickstart](/docs/get-started)
    
*   Features
    
    *   [Sessions](/docs/tracing-features/sessions)
        
    *   [Users](/docs/tracing-features/users)
        
    *   [Metadata](/docs/tracing-features/metadata)
        
    *   [Tags](/docs/tracing-features/tags)
        
    *   [Trace URL](/docs/tracing-features/url)
        
    *   [Log Levels](/docs/tracing-features/log-levels)
        
    *   [Sampling](/docs/tracing-features/sampling)
        
    
*   SDKs
    
    *   [Overview](/docs/sdk/overview)
        
    *   Python
        
        *   [Decorators](/docs/sdk/python/decorators)
            
        *   [Example Notebook](/docs/sdk/python/example)
            
        *   [Low-level SDK](/docs/sdk/python/low-level-sdk)
            
        *   [Reference ↗ (opens in a new tab)](https://python.reference.langfuse.com)
            
        
    *   JS/TS
        
        *   [Guide](/docs/sdk/typescript/guide)
            
        *   [Guide (Web)](/docs/sdk/typescript/guide-web)
            
        *   [Example (Vercel AI)](/docs/sdk/typescript/example-vercel-ai)
            
        *   [Reference ↗ (opens in a new tab)](https://js.reference.langfuse.com)
            
        
    
*   Integrations
    
    *   [Overview](/docs/integrations/overview)
        
    *   OpenAI SDK
        
        *   Python
            
            *   [Get Started](/docs/integrations/openai/python/get-started)
                
            *   [Track Errors](/docs/integrations/openai/python/track-errors)
                
            *   [Example Notebook](/docs/integrations/openai/python/examples)
                
            *   [Assistants API](/docs/integrations/openai/python/assistants-api)
                
            *   [Structured Outputs](/docs/integrations/openai/python/structured-outputs)
                
            
        *   JS/TS
            
            *   [Get Started](/docs/integrations/openai/js/get-started)
                
            *   [Example Notebook](/docs/integrations/openai/js/examples)
                
            
        
    *   Langchain
        
        *   [Tracing](/docs/integrations/langchain/tracing)
            
        *   [Example Python](/docs/integrations/langchain/example-python)
            
        *   [Example JS](/docs/integrations/langchain/example-javascript)
            
        *   [Example LangGraph](/docs/integrations/langchain/example-python-langgraph)
            
        *   [Example LangServe](/docs/integrations/langchain/example-python-langserve)
            
        *   [Upgrade Paths](/docs/integrations/langchain/upgrade-paths)
            
        
    *   LlamaIndex
        
        *   [Get Started](/docs/integrations/llama-index/get-started)
            
        *   [Example (Python)](/docs/integrations/llama-index/example-python)
            
        
    *   Haystack
        
        *   [Get Started](/docs/integrations/haystack/get-started)
            
        *   [Example (Python)](/docs/integrations/haystack/example-python)
            
        
    *   LiteLLM
        
        *   [Tracing](/docs/integrations/litellm/tracing)
            
        *   [Example Proxy (Python)](/docs/integrations/litellm/example-proxy-python)
            
        *   [Example Proxy (JS/TS)](/docs/integrations/litellm/example-proxy-js)
            
        
    *   [Vercel AI SDK](/docs/integrations/vercel-ai-sdk)
        
    *   [Dify.AI](/docs/integrations/dify)
        
    *   [Instructor](/docs/integrations/instructor)
        
    *   Mirascope
        
        *   [Tracing](/docs/integrations/mirascope/tracing)
            
        *   [Example Notebook](/docs/integrations/mirascope/example-python)
            
        
    *   [Flowise](/docs/integrations/flowise)
        
    *   [Langflow](/docs/integrations/langflow)
        
    
*   [Query Traces](/docs/query-traces)
    
*   Develop
*   Prompt Management
    
    *   [Get Started](/docs/prompts/get-started)
        
    *   [Example OpenAI Functions](/docs/prompts/example-openai-functions)
        
    *   [Example Langchain (Py)](/docs/prompts/example-langchain)
        
    *   [Example Langchain (JS)](/docs/prompts/example-langchain-js)
        
    
*   [Playground](/docs/playground)
    
*   [Fine-tuning](/docs/fine-tuning)
    
*   Monitor
*   Analytics
    
    *   [Overview](/docs/analytics/overview)
        
    *   [PostHog Integration](/docs/analytics/posthog)
        
    *   [Daily Metrics API](/docs/analytics/daily-metrics-api)
        
    
*   [Model Usage & Cost](/docs/model-usage-and-cost)
    
*   Scores & Evaluation
    
    *   [Overview](/docs/scores/overview)
        
    *   [Annotation in UI](/docs/scores/annotation)
        
    *   [User Feedback](/docs/scores/user-feedback)
        
    *   [Model-based Evaluation](/docs/scores/model-based-evals)
        
    *   [Custom via SDKs/API](/docs/scores/custom)
        
    
*   LLM Security
    
    *   [Overview](/docs/security/overview)
        
    *   [Example Python](/docs/security/example-python)
        
    
*   Test
*   [Experimentation](/docs/experimentation)
    
*   Datasets
    
    *   [Overview](/docs/datasets/overview)
        
    *   [Cookbook](/docs/datasets/python-cookbook)
        
    
*   References
*   [API ↗ (opens in a new tab)](https://api.reference.langfuse.com)
    
*   [Python SDK ↗ (opens in a new tab)](https://python.reference.langfuse.com)
    
*   [JS SDK ↗ (opens in a new tab)](https://js.reference.langfuse.com)
    
*   More
*   [Access Control (RBAC)](/docs/rbac)
    
*   [Data Security & Privacy](/docs/data-security-privacy)
    
*   [Open Source](/docs/open-source)
    
*   [Roadmap](/docs/roadmap)
    
*   [Support ↗ (opens in a new tab)](/support)
    

Light

On This Page

*   [Python](#python)
    
*   [From v1.x.x to v2.x.x](#python2)
    
*   [JS/TS](#js)
    
*   [From v2.x.x to v3.x.x](#js3)
    
*   [From v1.x.x to v2.x.x](#js2)
    

[Question? Give us feedback → (opens in a new tab)](https://github.com/langfuse/langfuse-docs/issues/new?title=Feedback%20for%20%E2%80%9CUpgrade%20Paths%3A%20Langchain%20Integration%E2%80%9D&labels=feedback)
[Edit this page on GitHub](https://github.com/langfuse/langfuse-docs/tree/main/pages/docs/integrations/langchain/upgrade-paths.mdx)
Scroll to top

Docs

Integrations

Langchain

Upgrade Paths

Upgrade Paths: Langchain Integration
====================================

This doc is a collection of upgrade paths for different versions of the integration. If you want to add the integration to your project, you should start with the latest version and follow the [integration guide](/docs/integrations/langchain/tracing)
.

Lanfuse and Langchain are under active development. Thus, we are constantly improving the intgration. This means that we sometimes need to make breaking changes to our APIs or need to react to breaking changes in Langchain. We try to keep these to a minimum and to provide clear upgrade paths when we do make them.

**Python**

*   [From v1.x.x to v2.x.x](/docs/integrations/langchain/upgrade-paths#python2)
    

**JS/TS**

*   [From v2.x.x to v3.x.x](/docs/integrations/langchain/upgrade-paths#js3)
    
*   [From v1.x.x to v2.x.x](/docs/integrations/langchain/upgrade-paths#js2)
    

Python[](#python)

------------------

### From v1.x.x to v2.x.x[](#python2)

The `CallbackHandler` can be used in multiple invocations of a Langchain chain as shown below.

    from langfuse.callback import CallbackHandler
    langfuse_handler = CallbackHandler(PUBLIC_KEY, SECRET_KEY)
     
    # Setup Langchain
    from langchain.chains import LLMChain
    ...
    chain = LLMChain(llm=llm, prompt=prompt, callbacks=[langfuse_handler])
     
    # Add Langfuse handler as callback
    chain.run(input="<first_user_input>", callbacks=[langfuse_handler])
    chain.run(input="<second_user_input>", callbacks=[langfuse_handler])
     

So far, invoking the chain multiple times would group the observations in one trace.

    TRACE
    |
    |-- SPAN: Retrieval
    |   |
    |   |-- SPAN: LLM Chain
    |   |   |
    |   |   |-- GENERATION: ChatOpenAi
    |-- SPAN: Retrieval
    |   |
    |   |-- SPAN: LLM Chain
    |   |   |
    |   |   |-- GENERATION: ChatOpenAi

We changed this, so that each invocation will end up on its own trace. This allows us to derive the user inputs and outputs to Langchain applications.

    TRACE_1
    |
    |-- SPAN: Retrieval
    |   |
    |   |-- SPAN: LLM Chain
    |   |   |
    |   |   |-- GENERATION: ChatOpenAi
     
    TRACE_2
    |
    |-- SPAN: Retrieval
    |   |
    |   |-- SPAN: LLM Chain
    |   |   |
    |   |   |-- GENERATION: ChatOpenAi

If you still want to group multiple invocations on one trace, you can use the Langfuse SDK combined with the Langchain integration ([more details](/docs/integrations/langchain/tracing)
).

    from langfuse import Langfuse
    langfuse = Langfuse()
     
    # Get Langchain handler for a trace
    trace = langfuse.trace()
    langfuse_handler = trace.get_langchain_handler()
     
    # langfuse_handler will use the trace for all invocations

JS/TS[](#js)

-------------

### From v2.x.x to v3.x.x[](#js3)

Requires [`langchain ^0.1.10` (opens in a new tab)](https://github.com/langchain-ai/langchainjs/releases/tag/0.1.10)
. Langchain released a new stable version of the Callback Handler interface and this version of the Langfuse SDK implements it. Older versions are no longer supported.

### From v1.x.x to v2.x.x[](#js2)

The `CallbackHandler` can be used in multiple invocations of a Langchain chain as shown below.

    import { CallbackHandler } from "langfuse-langchain";
     
    // create a handler
    const langfuseHandler = new CallbackHandler({
      publicKey: LANGFUSE_PUBLIC_KEY,
      secretKey: LANGFUSE_SECRET_KEY,
    });
     
    import { LLMChain } from "langchain/chains";
     
    // create a chain
    const chain = new LLMChain({
      llm: model,
      prompt,
      callbacks: [langfuseHandler],
    });
     
    // execute the chain
    await chain.call(
      { product: "<user_input_one>" },
      { callbacks: [langfuseHandler] }
    );
    await chain.call(
      { product: "<user_input_two>" },
      { callbacks: [langfuseHandler] }
    );

So far, invoking the chain multiple times would group the observations in one trace.

    TRACE
    |
    |-- SPAN: Retrieval
    |   |
    |   |-- SPAN: LLM Chain
    |   |   |
    |   |   |-- GENERATION: ChatOpenAi
    |-- SPAN: Retrieval
    |   |
    |   |-- SPAN: LLM Chain
    |   |   |
    |   |   |-- GENERATION: ChatOpenAi

We changed this, so that each invocation will end up on its own trace. This is a more sensible default setting for most users.

    TRACE_1
    |
    |-- SPAN: Retrieval
    |   |
    |   |-- SPAN: LLM Chain
    |   |   |
    |   |   |-- GENERATION: ChatOpenAi
     
    TRACE_2
    |
    |-- SPAN: Retrieval
    |   |
    |   |-- SPAN: LLM Chain
    |   |   |
    |   |   |-- GENERATION: ChatOpenAi

If you still want to group multiple invocations on one trace, you can use the Langfuse SDK combined with the Langchain integration ([more details](/docs/integrations/langchain/tracing)
).

    const trace = langfuse.trace({ id: "special-id" });
    // CallbackHandler will use the trace with the id "special-id" for all invocations
    const langfuseHandler = new CallbackHandler({ root: trace });

[Example LangServe](/docs/integrations/langchain/example-python-langserve "Example LangServe")
[Get Started](/docs/integrations/llama-index/get-started "Get Started")

### Was this page useful?

YesCould be better

### Questions? We're here to help

[GitHub Q&AGitHub](/gh-support)
Chat [Email](/cdn-cgi/l/email-protection#d0a3a5a0a0bfa2a490bcb1beb7b6a5a3b5feb3bfbd)
[Talk to sales](/schedule-demo)

### Subscribe to updates

Get updates

Light

* * *

Platform

*   [LLM Tracing](/docs/tracing)
    
*   [Prompt Management](/docs/prompts/get-started)
    
*   [Evaluation](/docs/scores/overview)
    
*   [Manual Annotation](/docs/scores/annotation)
    
*   [Datasets](/docs/datasets/overview)
    
*   [Metrics](/docs/analytics)
    
*   [Playground](/docs/playground)
    

Integrations

*   [Python SDK](/docs/sdk/python)
    
*   [JS/TS SDK](/docs/sdk/typescript/guide)
    
*   [OpenAI SDK](/docs/integrations/openai/get-started)
    
*   [Langchain](/docs/integrations/langchain/tracing)
    
*   [Llama-Index](/docs/integrations/llama-index/get-started)
    
*   [Litellm](/docs/integrations/litellm)
    
*   [Dify](/docs/integrations/dify)
    
*   [Flowise](/docs/integrations/flowise)
    
*   [Langflow](/docs/integrations/langflow)
    
*   [Vercel AI SDK](/docs/sdk/typescript/example-vercel-ai)
    
*   [Instructor](/docs/integrations/instructor)
    
*   [Mirascope](/docs/integrations/mirascope)
    
*   [API](https://api.reference.langfuse.com/)
    

Resources

*   [Documentation](/docs)
    
*   [Interactive Demo](/demo)
    
*   [Video demo (3 min)](/video)
    
*   [Changelog](/changelog)
    
*   [Roadmap](/docs/roadmap)
    
*   [Pricing](/pricing)
    
*   [Enterprise](/enterprise)
    
*   [Self-hosting](/docs/deployment/self-host)
    
*   [Open Source](/docs/open-source)
    
*   [Why Langfuse?](/why)
    
*   [Status](https://status.langfuse.com)
    

About

*   [Blog](/blog)
    
*   [Careers](/careers)
    3
*   [About us](/about)
    
*   [Support](/support)
    
*   [Schedule Demo](/schedule-demo)
    
*   [OSS Friends](/oss-friends)
    

Legal

*   [Security](/security)
    
*   [Imprint](/imprint)
    
*   [Terms](/terms)
    
*   [Privacy](/privacy)
    

© 2022-2024 Langfuse GmbH / Finto Technologies Inc.