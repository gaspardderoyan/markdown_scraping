---
domain: langfuse.com
path: /docs/prompts/example-langchain-js
url: https://langfuse.com/docs/prompts/example-langchain-js
---

[Join us in Engineering & DevRel →We're hiring. Join us in Product Eng, Backend Eng, and DevRel →](/careers)

[![Langfuse Logo](https://langfuse.com/langfuse_logo_white.svg)![Langfuse Logo](https://langfuse.com/langfuse_logo.svg)](/)
[DocsDocs](/docs)
[PricingPricing](/pricing)
[ChangelogChangelog](/changelog)
[BlogBlog](/blog)

Demo

[Discord](https://discord.langfuse.com)
[](https://x.com/langfuse)
[GitHub](https://github.com/langfuse/langfuse "GitHub Repository")
[Sign Up](https://cloud.langfuse.com)

*   Docs
    
    [Guides](/guides)
    [FAQ](/faq)
    
*   [Overview](/docs)
    
*   [Interactive Demo](/docs/demo)
    
*   Self-host
    
    *   [Local (docker compose)](/docs/deployment/local)
        
    *   [Self-host (docker)](/docs/deployment/self-host)
        
    
*   Tracing
*   [Introduction](/docs/tracing)
    
*   [Quickstart](/docs/get-started)
    
*   Features
    
    *   [Sessions](/docs/tracing-features/sessions)
        
    *   [Users](/docs/tracing-features/users)
        
    *   [Metadata](/docs/tracing-features/metadata)
        
    *   [Tags](/docs/tracing-features/tags)
        
    *   [Trace URL](/docs/tracing-features/url)
        
    *   [Log Levels](/docs/tracing-features/log-levels)
        
    *   [Sampling](/docs/tracing-features/sampling)
        
    
*   SDKs
    
    *   [Overview](/docs/sdk/overview)
        
    *   Python
        
        *   [Decorators](/docs/sdk/python/decorators)
            
        *   [Example Notebook](/docs/sdk/python/example)
            
        *   [Low-level SDK](/docs/sdk/python/low-level-sdk)
            
        *   [Reference ↗ (opens in a new tab)](https://python.reference.langfuse.com)
            
        
    *   JS/TS
        
        *   [Guide](/docs/sdk/typescript/guide)
            
        *   [Guide (Web)](/docs/sdk/typescript/guide-web)
            
        *   [Example (Vercel AI)](/docs/sdk/typescript/example-vercel-ai)
            
        *   [Reference ↗ (opens in a new tab)](https://js.reference.langfuse.com)
            
        
    
*   Integrations
    
    *   [Overview](/docs/integrations/overview)
        
    *   OpenAI SDK
        
        *   Python
            
            *   [Get Started](/docs/integrations/openai/python/get-started)
                
            *   [Track Errors](/docs/integrations/openai/python/track-errors)
                
            *   [Example Notebook](/docs/integrations/openai/python/examples)
                
            *   [Assistants API](/docs/integrations/openai/python/assistants-api)
                
            *   [Structured Outputs](/docs/integrations/openai/python/structured-outputs)
                
            
        *   JS/TS
            
            *   [Get Started](/docs/integrations/openai/js/get-started)
                
            *   [Example Notebook](/docs/integrations/openai/js/examples)
                
            
        
    *   Langchain
        
        *   [Tracing](/docs/integrations/langchain/tracing)
            
        *   [Example Python](/docs/integrations/langchain/example-python)
            
        *   [Example JS](/docs/integrations/langchain/example-javascript)
            
        *   [Example LangGraph](/docs/integrations/langchain/example-python-langgraph)
            
        *   [Example LangServe](/docs/integrations/langchain/example-python-langserve)
            
        *   [Upgrade Paths](/docs/integrations/langchain/upgrade-paths)
            
        
    *   LlamaIndex
        
        *   [Get Started](/docs/integrations/llama-index/get-started)
            
        *   [Example (Python)](/docs/integrations/llama-index/example-python)
            
        
    *   Haystack
        
        *   [Get Started](/docs/integrations/haystack/get-started)
            
        *   [Example (Python)](/docs/integrations/haystack/example-python)
            
        
    *   LiteLLM
        
        *   [Tracing](/docs/integrations/litellm/tracing)
            
        *   [Example Proxy (Python)](/docs/integrations/litellm/example-proxy-python)
            
        *   [Example Proxy (JS/TS)](/docs/integrations/litellm/example-proxy-js)
            
        
    *   [Vercel AI SDK](/docs/integrations/vercel-ai-sdk)
        
    *   [Dify.AI](/docs/integrations/dify)
        
    *   [Instructor](/docs/integrations/instructor)
        
    *   Mirascope
        
        *   [Tracing](/docs/integrations/mirascope/tracing)
            
        *   [Example Notebook](/docs/integrations/mirascope/example-python)
            
        
    *   [Flowise](/docs/integrations/flowise)
        
    *   [Langflow](/docs/integrations/langflow)
        
    
*   [Query Traces](/docs/query-traces)
    
*   Develop
*   Prompt Management
    
    *   [Get Started](/docs/prompts/get-started)
        
    *   [Example OpenAI Functions](/docs/prompts/example-openai-functions)
        
    *   [Example Langchain (Py)](/docs/prompts/example-langchain)
        
    *   [Example Langchain (JS)](/docs/prompts/example-langchain-js)
        
    
*   [Playground](/docs/playground)
    
*   [Fine-tuning](/docs/fine-tuning)
    
*   Monitor
*   Analytics
    
    *   [Overview](/docs/analytics/overview)
        
    *   [PostHog Integration](/docs/analytics/posthog)
        
    *   [Daily Metrics API](/docs/analytics/daily-metrics-api)
        
    
*   [Model Usage & Cost](/docs/model-usage-and-cost)
    
*   Scores & Evaluation
    
    *   [Overview](/docs/scores/overview)
        
    *   [Annotation in UI](/docs/scores/annotation)
        
    *   [User Feedback](/docs/scores/user-feedback)
        
    *   [Model-based Evaluation](/docs/scores/model-based-evals)
        
    *   [Custom via SDKs/API](/docs/scores/custom)
        
    
*   LLM Security
    
    *   [Overview](/docs/security/overview)
        
    *   [Example Python](/docs/security/example-python)
        
    
*   Test
*   [Experimentation](/docs/experimentation)
    
*   Datasets
    
    *   [Overview](/docs/datasets/overview)
        
    *   [Cookbook](/docs/datasets/python-cookbook)
        
    
*   References
*   [API ↗ (opens in a new tab)](https://api.reference.langfuse.com)
    
*   [Python SDK ↗ (opens in a new tab)](https://python.reference.langfuse.com)
    
*   [JS SDK ↗ (opens in a new tab)](https://js.reference.langfuse.com)
    
*   More
*   [Access Control (RBAC)](/docs/rbac)
    
*   [Data Security & Privacy](/docs/data-security-privacy)
    
*   [Open Source](/docs/open-source)
    
*   [Roadmap](/docs/roadmap)
    
*   [Support ↗ (opens in a new tab)](/support)
    

Light

On This Page

*   [Simple example](#simple-example)
    
*   [Add new prompt](#add-new-prompt)
    
*   [Run example](#run-example)
    
*   [Get current prompt version from Langfuse](#get-current-prompt-version-from-langfuse)
    
*   [Transform prompt into Langchain PromptTemplate](#transform-prompt-into-langchain-prompttemplate)
    
*   [Setup Langfuse Tracing for Langchain JS](#setup-langfuse-tracing-for-langchain-js)
    
*   [Create chain](#create-chain)
    
*   [Invoke chain](#invoke-chain)
    
*   [View trace in Langfuse](#view-trace-in-langfuse)
    
*   [OpenAI functions and JsonOutputFunctionsParser](#openai-functions-and-jsonoutputfunctionsparser)
    
*   [Add prompt to Langfuse](#add-prompt-to-langfuse)
    
*   [Fetch prompt](#fetch-prompt)
    
*   [Build chain](#build-chain)
    
*   [Invoke chain](#invoke-chain-1)
    
*   [View trace in Langfuse](#view-trace-in-langfuse-1)
    

[Question? Give us feedback → (opens in a new tab)](https://github.com/langfuse/langfuse-docs/issues/new?title=Feedback%20for%20%E2%80%9CExample%3A%20Langfuse%20Prompt%20Management%20with%20Langchain%20(JS)%E2%80%9D&labels=feedback)
[Edit this page on GitHub](https://github.com/langfuse/langfuse-docs/tree/main/pages/docs/prompts/example-langchain-js.md)
Scroll to top

Docs

Prompt Management

Example Langchain (JS)

This is a Jupyter notebook

[Open on GitHub](https://github.com/langfuse/langfuse-docs/blob/main/cookbook/js_prompt_management_langchain.ipynb)
[Run on Google Colab](https://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/cookbook/js_prompt_management_langchain.ipynb)

Example: Langfuse Prompt Management with Langchain (JS)
=======================================================

Langfuse [Prompt Management (opens in a new tab)](https://langfuse.com/docs/prompts)
 helps to version control and manage prompts collaboratively in one place.

This example demonstrates how to use Langfuse Prompt Management together with Langchain JS.

    const langfuseParams = {
        publicKey: "",
        secretKey: "",
        baseUrl: "https://cloud.langfuse.com",
        flushAt: 1 // cookbook-only, send all events immediately
    }

    import {Langfuse} from "npm:langfuse"
    const langfuse = new Langfuse(langfuseParams)

Simple example[](#simple-example)

----------------------------------

### Add new prompt[](#add-new-prompt)

We add the prompt used in this example via the SDK. Alternatively, you can also edit and version the prompt in the Langfuse UI.

*   `Name` that identifies the prompt in Langfuse Prompt Management
*   Prompt with `topic` variable
*   Config including `modelName`, `temperature`
*   `labels` to include `production` to immediately use prompt as the default

For the sake of this notebook, we will add the prompt in Langfuse and use it right away. Usually, you'd update the prompt from time to time in Langfuse and your application fetches the current production version.

    const prompt =  await langfuse.createPrompt({
        name: "jokes",
        prompt: "Tell me a joke about {{topic}}",
        config: {
          modelName: "gpt-4",
          temperature: 1,
        }, // optionally, add configs (e.g. model parameters or model tools)
        labels: ["production"] // directly promote to production
    });

Prompt in Langfuse

![Prompt in Langfuse](https://langfuse.com/images/cookbook/js_prompt_management_langchain_simple_prompt.png)

### Run example[](#run-example)

#### Get current prompt version from Langfuse[](#get-current-prompt-version-from-langfuse)

    const prompt = await langfuse.getPrompt("jokes")

The prompt includes the prompt string

    prompt.prompt

    [32m"Tell me a joke about {{topic}}"[39m\
\
and the config object\
\
    prompt.config\
\
    { modelName: [32m"gpt-4"[39m, temperature: [33m1[39m }\
\
#### Transform prompt into Langchain PromptTemplate[](#transform-prompt-into-langchain-prompttemplate)\
\
Use the utility method `.getLangchainPrompt()` to transform the Langfuse prompt into a string that can be used in Langchain.\
\
Context: Langfuse declares input variables in prompt templates using double brackets (`{{input variable}}`). Langchain uses single brackets for declaring input variables in PromptTemplates (`{input variable}`). The utility method `.getLangchainPrompt()` replaces the double brackets with single brackets.\
\
    import { PromptTemplate } from "npm:@langchain/core/prompts"\
     \
    const promptTemplate = PromptTemplate.fromTemplate(\
        prompt.getLangchainPrompt()\
      );\
\
#### Setup Langfuse Tracing for Langchain JS[](#setup-langfuse-tracing-for-langchain-js)\
\
We'll use the native [Langfuse Tracing for Langchain JS (opens in a new tab)](https://langfuse.com/docs/integrations/langchain)\
 when executing this chain. This is fully optional and can be used independently from Prompt Management.\
\
    import { CallbackHandler } from "npm:langfuse-langchain"\
    const langfuseLangchainHandler = new CallbackHandler(langfuseParams)\
\
#### Create chain[](#create-chain)\
\
We use the `modelName` and `temperature` stored in `prompt.config`.\
\
    import { ChatOpenAI } from "npm:@langchain/openai"\
    import { RunnableSequence } from "npm:@langchain/core/runnables";\
     \
    const model = new ChatOpenAI({\
        modelName: prompt.config.modelName,\
        temperature: prompt.config.temperature\
    });\
    const chain = RunnableSequence.from([promptTemplate, model]);\
\
#### Invoke chain[](#invoke-chain)\
\
    const res = await chain.invoke(\
        { topic: "Europe and the Americas" },\
        { callbacks: [langfuseLangchainHandler] }\
    );\
\
### View trace in Langfuse[](#view-trace-in-langfuse)\
\
As we passed the langfuse callback handler, we can explore the execution trace in Langfuse.\
\
![Trace in Langfuse](https://langfuse.com/images/cookbook/js_prompt_management_langchain_simple_trace.png)\
\
OpenAI functions and JsonOutputFunctionsParser[](#openai-functions-and-jsonoutputfunctionsparser)\
\
--------------------------------------------------------------------------------------------------\
\
### Add prompt to Langfuse[](#add-prompt-to-langfuse)\
\
    const prompt =  await langfuse.createPrompt({\
        name: "extractor",\
        prompt: "Extracts fields from the input.",\
        config: {\
          modelName: "gpt-4",\
          temperature: 0,\
          schema: {\
            type: "object",\
            properties: {\
              tone: {\
                type: "string",\
                enum: ["positive", "negative"],\
                description: "The overall tone of the input",\
              },\
              word_count: {\
                type: "number",\
                description: "The number of words in the input",\
              },\
              chat_response: {\
                type: "string",\
                description: "A response to the human's input",\
              },\
            },\
            required: ["tone", "word_count", "chat_response"],\
          }\
        }, // optionally, add configs (e.g. model parameters or model tools)\
        labels: ["production"] // directly promote to production\
    });\
\
Prompt in Langfuse\
\
![Prompt in Langfuse](https://langfuse.com/images/cookbook/js_prompt_management_langchain_json_extraction_prompt.png)\
\
### Fetch prompt[](#fetch-prompt)\
\
    const extractorPrompt = await langfuse.getPrompt("extractor")\
\
Transform into schema\
\
    const extractionFunctionSchema = {\
        name: "extractor",\
        description: prompt.prompt,\
        parameters: prompt.config.schema,\
    }\
\
### Build chain[](#build-chain)\
\
    import { ChatOpenAI } from "npm:@langchain/openai";\
    import { JsonOutputFunctionsParser } from "npm:langchain/output_parsers";\
     \
    // Instantiate the parser\
    const parser = new JsonOutputFunctionsParser();\
     \
    // Instantiate the ChatOpenAI class\
    const model = new ChatOpenAI({ \
        modelName: prompt.config.modelName,\
        temperature: prompt.config.temperature\
    });\
     \
    // Create a new runnable, bind the function to the model, and pipe the output through the parser\
    const runnable = model\
      .bind({\
        functions: [extractionFunctionSchema],\
        function_call: { name: "extractor" },\
      })\
      .pipe(parser);\
\
### Invoke chain[](#invoke-chain-1)\
\
    import { HumanMessage } from "npm:@langchain/core/messages";\
     \
    // Invoke the runnable with an input\
    const result = await runnable.invoke(\
        [new HumanMessage("What a beautiful day!")],\
        { callbacks: [langfuseLangchainHandler] }\
    );\
\
### View trace in Langfuse[](#view-trace-in-langfuse-1)\
\
![Trace in Langfuse](https://langfuse.com/images/cookbook/js_prompt_management_langchain_json_extraction_trace.png)\
\
[Example Langchain (Py)](/docs/prompts/example-langchain "Example Langchain (Py)")\
[Playground](/docs/playground "Playground")\
\
### Was this page useful?\
\
YesCould be better\
\
### Questions? We're here to help\
\
[GitHub Q&AGitHub](/gh-support)\
Chat [Email](/cdn-cgi/l/email-protection#dcafa9acacb3aea89cb0bdb2bbbaa9afb9f2bfb3b1)\
[Talk to sales](/schedule-demo)\
\
### Subscribe to updates\
\
Get updates\
\
Light\
\
* * *\
\
Platform\
\
*   [LLM Tracing](/docs/tracing)\
    \
*   [Prompt Management](/docs/prompts/get-started)\
    \
*   [Evaluation](/docs/scores/overview)\
    \
*   [Manual Annotation](/docs/scores/annotation)\
    \
*   [Datasets](/docs/datasets/overview)\
    \
*   [Metrics](/docs/analytics)\
    \
*   [Playground](/docs/playground)\
    \
\
Integrations\
\
*   [Python SDK](/docs/sdk/python)\
    \
*   [JS/TS SDK](/docs/sdk/typescript/guide)\
    \
*   [OpenAI SDK](/docs/integrations/openai/get-started)\
    \
*   [Langchain](/docs/integrations/langchain/tracing)\
    \
*   [Llama-Index](/docs/integrations/llama-index/get-started)\
    \
*   [Litellm](/docs/integrations/litellm)\
    \
*   [Dify](/docs/integrations/dify)\
    \
*   [Flowise](/docs/integrations/flowise)\
    \
*   [Langflow](/docs/integrations/langflow)\
    \
*   [Vercel AI SDK](/docs/sdk/typescript/example-vercel-ai)\
    \
*   [Instructor](/docs/integrations/instructor)\
    \
*   [Mirascope](/docs/integrations/mirascope)\
    \
*   [API](https://api.reference.langfuse.com/)\
    \
\
Resources\
\
*   [Documentation](/docs)\
    \
*   [Interactive Demo](/demo)\
    \
*   [Video demo (3 min)](/video)\
    \
*   [Changelog](/changelog)\
    \
*   [Roadmap](/docs/roadmap)\
    \
*   [Pricing](/pricing)\
    \
*   [Enterprise](/enterprise)\
    \
*   [Self-hosting](/docs/deployment/self-host)\
    \
*   [Open Source](/docs/open-source)\
    \
*   [Why Langfuse?](/why)\
    \
*   [Status](https://status.langfuse.com)\
    \
\
About\
\
*   [Blog](/blog)\
    \
*   [Careers](/careers)\
    3\
*   [About us](/about)\
    \
*   [Support](/support)\
    \
*   [Schedule Demo](/schedule-demo)\
    \
*   [OSS Friends](/oss-friends)\
    \
\
Legal\
\
*   [Security](/security)\
    \
*   [Imprint](/imprint)\
    \
*   [Terms](/terms)\
    \
*   [Privacy](/privacy)\
    \
\
© 2022-2024 Langfuse GmbH / Finto Technologies Inc.