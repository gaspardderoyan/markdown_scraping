---
domain: langfuse.com
path: /docs/integrations/langchain/example-python-langserve
url: https://langfuse.com/docs/integrations/langchain/example-python-langserve
---

[Join us in Engineering & DevRel â†’We're hiring. Join us in Product Eng, Backend Eng, and DevRel â†’](/careers)

[![Langfuse Logo](https://langfuse.com/langfuse_logo_white.svg)![Langfuse Logo](https://langfuse.com/langfuse_logo.svg)](/)
[DocsDocs](/docs)
[PricingPricing](/pricing)
[ChangelogChangelog](/changelog)
[BlogBlog](/blog)

Demo

[Discord](https://discord.langfuse.com)
[](https://x.com/langfuse)
[GitHub](https://github.com/langfuse/langfuse "GitHub Repository")
[Sign Up](https://cloud.langfuse.com)

*   Docs
    
    [Guides](/guides)
    [FAQ](/faq)
    
*   [Overview](/docs)
    
*   [Interactive Demo](/docs/demo)
    
*   Self-host
    
    *   [Local (docker compose)](/docs/deployment/local)
        
    *   [Self-host (docker)](/docs/deployment/self-host)
        
    
*   Tracing
*   [Introduction](/docs/tracing)
    
*   [Quickstart](/docs/get-started)
    
*   Features
    
    *   [Sessions](/docs/tracing-features/sessions)
        
    *   [Users](/docs/tracing-features/users)
        
    *   [Metadata](/docs/tracing-features/metadata)
        
    *   [Tags](/docs/tracing-features/tags)
        
    *   [Trace URL](/docs/tracing-features/url)
        
    *   [Log Levels](/docs/tracing-features/log-levels)
        
    *   [Sampling](/docs/tracing-features/sampling)
        
    
*   SDKs
    
    *   [Overview](/docs/sdk/overview)
        
    *   Python
        
        *   [Decorators](/docs/sdk/python/decorators)
            
        *   [Example Notebook](/docs/sdk/python/example)
            
        *   [Low-level SDK](/docs/sdk/python/low-level-sdk)
            
        *   [Reference â†— (opens in a new tab)](https://python.reference.langfuse.com)
            
        
    *   JS/TS
        
        *   [Guide](/docs/sdk/typescript/guide)
            
        *   [Guide (Web)](/docs/sdk/typescript/guide-web)
            
        *   [Example (Vercel AI)](/docs/sdk/typescript/example-vercel-ai)
            
        *   [Reference â†— (opens in a new tab)](https://js.reference.langfuse.com)
            
        
    
*   Integrations
    
    *   [Overview](/docs/integrations/overview)
        
    *   OpenAI SDK
        
        *   Python
            
            *   [Get Started](/docs/integrations/openai/python/get-started)
                
            *   [Track Errors](/docs/integrations/openai/python/track-errors)
                
            *   [Example Notebook](/docs/integrations/openai/python/examples)
                
            *   [Assistants API](/docs/integrations/openai/python/assistants-api)
                
            *   [Structured Outputs](/docs/integrations/openai/python/structured-outputs)
                
            
        *   JS/TS
            
            *   [Get Started](/docs/integrations/openai/js/get-started)
                
            *   [Example Notebook](/docs/integrations/openai/js/examples)
                
            
        
    *   Langchain
        
        *   [Tracing](/docs/integrations/langchain/tracing)
            
        *   [Example Python](/docs/integrations/langchain/example-python)
            
        *   [Example JS](/docs/integrations/langchain/example-javascript)
            
        *   [Example LangGraph](/docs/integrations/langchain/example-python-langgraph)
            
        *   [Example LangServe](/docs/integrations/langchain/example-python-langserve)
            
        *   [Upgrade Paths](/docs/integrations/langchain/upgrade-paths)
            
        
    *   LlamaIndex
        
        *   [Get Started](/docs/integrations/llama-index/get-started)
            
        *   [Example (Python)](/docs/integrations/llama-index/example-python)
            
        
    *   Haystack
        
        *   [Get Started](/docs/integrations/haystack/get-started)
            
        *   [Example (Python)](/docs/integrations/haystack/example-python)
            
        
    *   LiteLLM
        
        *   [Tracing](/docs/integrations/litellm/tracing)
            
        *   [Example Proxy (Python)](/docs/integrations/litellm/example-proxy-python)
            
        *   [Example Proxy (JS/TS)](/docs/integrations/litellm/example-proxy-js)
            
        
    *   [Vercel AI SDK](/docs/integrations/vercel-ai-sdk)
        
    *   [Dify.AI](/docs/integrations/dify)
        
    *   [Instructor](/docs/integrations/instructor)
        
    *   Mirascope
        
        *   [Tracing](/docs/integrations/mirascope/tracing)
            
        *   [Example Notebook](/docs/integrations/mirascope/example-python)
            
        
    *   [Flowise](/docs/integrations/flowise)
        
    *   [Langflow](/docs/integrations/langflow)
        
    
*   [Query Traces](/docs/query-traces)
    
*   Develop
*   Prompt Management
    
    *   [Get Started](/docs/prompts/get-started)
        
    *   [Example OpenAI Functions](/docs/prompts/example-openai-functions)
        
    *   [Example Langchain (Py)](/docs/prompts/example-langchain)
        
    *   [Example Langchain (JS)](/docs/prompts/example-langchain-js)
        
    
*   [Playground](/docs/playground)
    
*   [Fine-tuning](/docs/fine-tuning)
    
*   Monitor
*   Analytics
    
    *   [Overview](/docs/analytics/overview)
        
    *   [PostHog Integration](/docs/analytics/posthog)
        
    *   [Daily Metrics API](/docs/analytics/daily-metrics-api)
        
    
*   [Model Usage & Cost](/docs/model-usage-and-cost)
    
*   Scores & Evaluation
    
    *   [Overview](/docs/scores/overview)
        
    *   [Annotation in UI](/docs/scores/annotation)
        
    *   [User Feedback](/docs/scores/user-feedback)
        
    *   [Model-based Evaluation](/docs/scores/model-based-evals)
        
    *   [Custom via SDKs/API](/docs/scores/custom)
        
    
*   LLM Security
    
    *   [Overview](/docs/security/overview)
        
    *   [Example Python](/docs/security/example-python)
        
    
*   Test
*   [Experimentation](/docs/experimentation)
    
*   Datasets
    
    *   [Overview](/docs/datasets/overview)
        
    *   [Cookbook](/docs/datasets/python-cookbook)
        
    
*   References
*   [API â†— (opens in a new tab)](https://api.reference.langfuse.com)
    
*   [Python SDK â†— (opens in a new tab)](https://python.reference.langfuse.com)
    
*   [JS SDK â†— (opens in a new tab)](https://js.reference.langfuse.com)
    
*   More
*   [Access Control (RBAC)](/docs/rbac)
    
*   [Data Security & Privacy](/docs/data-security-privacy)
    
*   [Open Source](/docs/open-source)
    
*   [Roadmap](/docs/roadmap)
    
*   [Support â†— (opens in a new tab)](/support)
    

Light

On This Page

*   [Setup](#setup)
    
*   [Simple LLM Call Example](#simple-llm-call-example)
    
*   [LCEL example](#lcel-example)
    
*   [Agent Example](#agent-example)
    

[Question? Give us feedback â†’ (opens in a new tab)](https://github.com/langfuse/langfuse-docs/issues/new?title=Feedback%20for%20%E2%80%9CCookbook%3A%20Langserve%20Integration%E2%80%9D&labels=feedback)
[Edit this page on GitHub](https://github.com/langfuse/langfuse-docs/tree/main/pages/docs/integrations/langchain/example-python-langserve.md)
Scroll to top

Docs

Integrations

Langchain

Example LangServe

This is a Jupyter notebook

[Open on GitHub](https://github.com/langfuse/langfuse-docs/blob/main/cookbook/integration_langserve.ipynb)
[Run on Google Colab](https://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/cookbook/integration_langserve.ipynb)

Cookbook: Langserve Integration
===============================

[Langserve (opens in a new tab)](https://python.langchain.com/docs/langserve/)
 (Python)

> LangServe helps developers deploy LangChain runnables and chains as a REST API.
> 
> This library is integrated with FastAPI and uses pydantic for data validation.
> 
> In addition, it provides a client that can be used to call into runnables deployed on a server. A JavaScript client is available in LangChain.js.

This cookbook demonstrates how to trace applications deployed via Langserve with Langfuse (using the [LangChain integration (opens in a new tab)](https://langfuse.com/docs/integrations/langchain)
). We'll run both the server and the client in this notebook.

Setup[](#setup)

----------------

Install dependencies and configure environment

    !pip install fastapi sse_starlette httpx langserve langfuse langchain-openai langchain

    import os
     
    # Get keys for your project from the project settings page
    # https://cloud.langfuse.com
    os.environ["LANGFUSE_PUBLIC_KEY"] = ""
    os.environ["LANGFUSE_SECRET_KEY"] = ""
    os.environ["LANGFUSE_HOST"] = "https://cloud.langfuse.com" # ðŸ‡ªðŸ‡º EU region
    # os.environ["LANGFUSE_HOST"] = "https://us.cloud.langfuse.com" # ðŸ‡ºðŸ‡¸ US region
     
    # Your openai key
    os.environ["OPENAI_API_KEY"] = ""

Simple LLM Call Example[](#simple-llm-call-example)

----------------------------------------------------

Initialize the Langfuse client and configure the LLM with Langfuse as callback handler. Add to Fastapi via Langserve's `add_routes()`.

    from langchain_openai import ChatOpenAI
    from langchain_core.runnables.config import RunnableConfig
    from langfuse import Langfuse
    from langfuse.callback import CallbackHandler
    from fastapi import FastAPI
    from langserve import add_routes
     
    langfuse_handler = CallbackHandler()
     
    # Tests the SDK connection with the server
    langfuse_handler.auth_check()
     
    llm = ChatOpenAI()
     
    config = RunnableConfig(callbacks=[langfuse_handler])
     
    llm_with_langfuse = llm.with_config(config)
     
    # Setup server
    app = FastAPI()
     
    # Add Langserve route
    add_routes(
        app,
        llm_with_langfuse,
        path="/test-simple-llm-call",
    )

_Note: We use TestClient in this example to be able to run the server in a notebook_

    from fastapi.testclient import TestClient
     
    # Initialize TestClient
    client = TestClient(app)
     
    # Test simple route
    response = client.post("/test-simple-llm-call/invoke", json={"input": "Tell me a joke?"})

Example trace: [https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/5f32e2e7-9508-4280-b47b-e0356bc3c81e (opens in a new tab)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/5f32e2e7-9508-4280-b47b-e0356bc3c81e)

![Trace of Langserve Simple LLM Call](https://langfuse.com/images/cookbook/integration_langserve_simple.png)

LCEL example[](#lcel-example)

------------------------------

    from langchain.prompts import ChatPromptTemplate
    from langchain.schema import StrOutputParser
    from langserve import add_routes
     
    # Create Chain
    prompt = ChatPromptTemplate.from_template("Tell me a joke about {topic}")
     
    chain = prompt | llm | StrOutputParser()
     
    # Add new route
    add_routes(
        app,
        chain.with_config(config),
        path="/test-chain",
    )
     
    # Test chain route
    response = client.post("/test-chain/invoke", json={"input": {"topic": "Berlin"}})

Example trace: [https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/261d1006-74ff-4b67-8baf-afdfc827aee2 (opens in a new tab)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/261d1006-74ff-4b67-8baf-afdfc827aee2)

![Trace of Langserve LCEL Example](https://langfuse.com/images/cookbook/integration_langserve_chain.png)

Agent Example[](#agent-example)

--------------------------------

    from langchain_core.tools import tool
    from langchain_core.utils.function_calling import convert_to_openai_tool
    from langchain.agents.format_scratchpad.openai_tools import (
        format_to_openai_tool_messages,
    )
    from langchain.agents import AgentExecutor
    from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser
    from langserve.pydantic_v1 import BaseModel
    from langchain_core.prompts import MessagesPlaceholder
     
    class Input(BaseModel):
        input: str
     
    prompt = ChatPromptTemplate.from_messages(
        [\
            ("system", "You are a helpful assistant."),\
            ("user", "{input}"),\
            MessagesPlaceholder(variable_name="agent_scratchpad"),\
        ]
    )
     
    @tool
    def word_length(word: str) -> int:
        """Returns a counter word"""
        return len(word)
     
    tools = [word_length]
     
    llm_with_tools = llm.bind(tools=[convert_to_openai_tool(tool) for tool in tools])
     
    agent = (
        {
            "input": lambda x: x["input"],
            "agent_scratchpad": lambda x: format_to_openai_tool_messages(
                x["intermediate_steps"]
            ),
        }
        | prompt
        | llm_with_tools
        | OpenAIToolsAgentOutputParser()
    )
    agent_executor = AgentExecutor(agent=agent, tools=tools)
     
    agent_config = RunnableConfig({"run_name": "agent"}, callbacks=[langfuse_handler])
     
    add_routes(
        app,
        agent_executor.with_types(input_type=Input).with_config(
            agent_config
        ),
        path="/test-agent",
    )
     
    response = client.post("/test-agent/invoke", json={"input": {"input": "How long is Leonardo DiCaprios last name?"}})

Example trace: [https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/ed1d57f9-2f35-4e72-8150-b061f21840a7 (opens in a new tab)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/ed1d57f9-2f35-4e72-8150-b061f21840a7)

![Trace of Langserve Agent example](https://langfuse.com/images/cookbook/integration_langserve_agent.png)

[Example LangGraph](/docs/integrations/langchain/example-python-langgraph "Example LangGraph")
[Upgrade Paths](/docs/integrations/langchain/upgrade-paths "Upgrade Paths")

### Was this page useful?

YesCould be better

### Questions? We're here to help

[GitHub Q&AGitHub](/gh-support)
Chat [Email](/cdn-cgi/l/email-protection#ff8c8a8f8f908d8bbf939e9198998a8c9ad19c9092)
[Talk to sales](/schedule-demo)

### Subscribe to updates

GetÂ updates

Light

* * *

Platform

*   [LLM Tracing](/docs/tracing)
    
*   [Prompt Management](/docs/prompts/get-started)
    
*   [Evaluation](/docs/scores/overview)
    
*   [Manual Annotation](/docs/scores/annotation)
    
*   [Datasets](/docs/datasets/overview)
    
*   [Metrics](/docs/analytics)
    
*   [Playground](/docs/playground)
    

Integrations

*   [Python SDK](/docs/sdk/python)
    
*   [JS/TS SDK](/docs/sdk/typescript/guide)
    
*   [OpenAI SDK](/docs/integrations/openai/get-started)
    
*   [Langchain](/docs/integrations/langchain/tracing)
    
*   [Llama-Index](/docs/integrations/llama-index/get-started)
    
*   [Litellm](/docs/integrations/litellm)
    
*   [Dify](/docs/integrations/dify)
    
*   [Flowise](/docs/integrations/flowise)
    
*   [Langflow](/docs/integrations/langflow)
    
*   [Vercel AI SDK](/docs/sdk/typescript/example-vercel-ai)
    
*   [Instructor](/docs/integrations/instructor)
    
*   [Mirascope](/docs/integrations/mirascope)
    
*   [API](https://api.reference.langfuse.com/)
    

Resources

*   [Documentation](/docs)
    
*   [Interactive Demo](/demo)
    
*   [Video demo (3 min)](/video)
    
*   [Changelog](/changelog)
    
*   [Roadmap](/docs/roadmap)
    
*   [Pricing](/pricing)
    
*   [Enterprise](/enterprise)
    
*   [Self-hosting](/docs/deployment/self-host)
    
*   [Open Source](/docs/open-source)
    
*   [Why Langfuse?](/why)
    
*   [Status](https://status.langfuse.com)
    

About

*   [Blog](/blog)
    
*   [Careers](/careers)
    3
*   [About us](/about)
    
*   [Support](/support)
    
*   [Schedule Demo](/schedule-demo)
    
*   [OSS Friends](/oss-friends)
    

Legal

*   [Security](/security)
    
*   [Imprint](/imprint)
    
*   [Terms](/terms)
    
*   [Privacy](/privacy)
    

Â© 2022-2024 Langfuse GmbH / Finto Technologies Inc.