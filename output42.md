---
domain: langfuse.com
path: /docs/integrations/openai/js/examples
url: https://langfuse.com/docs/integrations/openai/js/examples
---

[Join us in Engineering & DevRel →We're hiring. Join us in Product Eng, Backend Eng, and DevRel →](/careers)

[![Langfuse Logo](https://langfuse.com/langfuse_logo_white.svg)![Langfuse Logo](https://langfuse.com/langfuse_logo.svg)](/)
[DocsDocs](/docs)
[PricingPricing](/pricing)
[ChangelogChangelog](/changelog)
[BlogBlog](/blog)

Demo

[Discord](https://discord.langfuse.com)
[](https://x.com/langfuse)
[GitHub](https://github.com/langfuse/langfuse "GitHub Repository")
[Sign Up](https://cloud.langfuse.com)

*   Docs
    
    [Guides](/guides)
    [FAQ](/faq)
    
*   [Overview](/docs)
    
*   [Interactive Demo](/docs/demo)
    
*   Self-host
    
    *   [Local (docker compose)](/docs/deployment/local)
        
    *   [Self-host (docker)](/docs/deployment/self-host)
        
    
*   Tracing
*   [Introduction](/docs/tracing)
    
*   [Quickstart](/docs/get-started)
    
*   Features
    
    *   [Sessions](/docs/tracing-features/sessions)
        
    *   [Users](/docs/tracing-features/users)
        
    *   [Metadata](/docs/tracing-features/metadata)
        
    *   [Tags](/docs/tracing-features/tags)
        
    *   [Trace URL](/docs/tracing-features/url)
        
    *   [Log Levels](/docs/tracing-features/log-levels)
        
    *   [Sampling](/docs/tracing-features/sampling)
        
    
*   SDKs
    
    *   [Overview](/docs/sdk/overview)
        
    *   Python
        
        *   [Decorators](/docs/sdk/python/decorators)
            
        *   [Example Notebook](/docs/sdk/python/example)
            
        *   [Low-level SDK](/docs/sdk/python/low-level-sdk)
            
        *   [Reference ↗ (opens in a new tab)](https://python.reference.langfuse.com)
            
        
    *   JS/TS
        
        *   [Guide](/docs/sdk/typescript/guide)
            
        *   [Guide (Web)](/docs/sdk/typescript/guide-web)
            
        *   [Example (Vercel AI)](/docs/sdk/typescript/example-vercel-ai)
            
        *   [Reference ↗ (opens in a new tab)](https://js.reference.langfuse.com)
            
        
    
*   Integrations
    
    *   [Overview](/docs/integrations/overview)
        
    *   OpenAI SDK
        
        *   Python
            
            *   [Get Started](/docs/integrations/openai/python/get-started)
                
            *   [Track Errors](/docs/integrations/openai/python/track-errors)
                
            *   [Example Notebook](/docs/integrations/openai/python/examples)
                
            *   [Assistants API](/docs/integrations/openai/python/assistants-api)
                
            *   [Structured Outputs](/docs/integrations/openai/python/structured-outputs)
                
            
        *   JS/TS
            
            *   [Get Started](/docs/integrations/openai/js/get-started)
                
            *   [Example Notebook](/docs/integrations/openai/js/examples)
                
            
        
    *   Langchain
        
        *   [Tracing](/docs/integrations/langchain/tracing)
            
        *   [Example Python](/docs/integrations/langchain/example-python)
            
        *   [Example JS](/docs/integrations/langchain/example-javascript)
            
        *   [Example LangGraph](/docs/integrations/langchain/example-python-langgraph)
            
        *   [Example LangServe](/docs/integrations/langchain/example-python-langserve)
            
        *   [Upgrade Paths](/docs/integrations/langchain/upgrade-paths)
            
        
    *   LlamaIndex
        
        *   [Get Started](/docs/integrations/llama-index/get-started)
            
        *   [Example (Python)](/docs/integrations/llama-index/example-python)
            
        
    *   Haystack
        
        *   [Get Started](/docs/integrations/haystack/get-started)
            
        *   [Example (Python)](/docs/integrations/haystack/example-python)
            
        
    *   LiteLLM
        
        *   [Tracing](/docs/integrations/litellm/tracing)
            
        *   [Example Proxy (Python)](/docs/integrations/litellm/example-proxy-python)
            
        *   [Example Proxy (JS/TS)](/docs/integrations/litellm/example-proxy-js)
            
        
    *   [Vercel AI SDK](/docs/integrations/vercel-ai-sdk)
        
    *   [Dify.AI](/docs/integrations/dify)
        
    *   [Instructor](/docs/integrations/instructor)
        
    *   Mirascope
        
        *   [Tracing](/docs/integrations/mirascope/tracing)
            
        *   [Example Notebook](/docs/integrations/mirascope/example-python)
            
        
    *   [Flowise](/docs/integrations/flowise)
        
    *   [Langflow](/docs/integrations/langflow)
        
    
*   [Query Traces](/docs/query-traces)
    
*   Develop
*   Prompt Management
    
    *   [Get Started](/docs/prompts/get-started)
        
    *   [Example OpenAI Functions](/docs/prompts/example-openai-functions)
        
    *   [Example Langchain (Py)](/docs/prompts/example-langchain)
        
    *   [Example Langchain (JS)](/docs/prompts/example-langchain-js)
        
    
*   [Playground](/docs/playground)
    
*   [Fine-tuning](/docs/fine-tuning)
    
*   Monitor
*   Analytics
    
    *   [Overview](/docs/analytics/overview)
        
    *   [PostHog Integration](/docs/analytics/posthog)
        
    *   [Daily Metrics API](/docs/analytics/daily-metrics-api)
        
    
*   [Model Usage & Cost](/docs/model-usage-and-cost)
    
*   Scores & Evaluation
    
    *   [Overview](/docs/scores/overview)
        
    *   [Annotation in UI](/docs/scores/annotation)
        
    *   [User Feedback](/docs/scores/user-feedback)
        
    *   [Model-based Evaluation](/docs/scores/model-based-evals)
        
    *   [Custom via SDKs/API](/docs/scores/custom)
        
    
*   LLM Security
    
    *   [Overview](/docs/security/overview)
        
    *   [Example Python](/docs/security/example-python)
        
    
*   Test
*   [Experimentation](/docs/experimentation)
    
*   Datasets
    
    *   [Overview](/docs/datasets/overview)
        
    *   [Cookbook](/docs/datasets/python-cookbook)
        
    
*   References
*   [API ↗ (opens in a new tab)](https://api.reference.langfuse.com)
    
*   [Python SDK ↗ (opens in a new tab)](https://python.reference.langfuse.com)
    
*   [JS SDK ↗ (opens in a new tab)](https://js.reference.langfuse.com)
    
*   More
*   [Access Control (RBAC)](/docs/rbac)
    
*   [Data Security & Privacy](/docs/data-security-privacy)
    
*   [Open Source](/docs/open-source)
    
*   [Roadmap](/docs/roadmap)
    
*   [Support ↗ (opens in a new tab)](/support)
    

Light

On This Page

*   [Setup](#setup)
    
*   [1\. Environment Variables](#1-environment-variables)
    
*   [2\. InitParams](#2-initparams)
    
*   [Examples](#examples)
    
*   [Chat completion](#chat-completion)
    
*   [Chat completion (streaming)](#chat-completion-streaming)
    
*   [Add additional metadata and parameters](#add-additional-metadata-and-parameters)
    
*   [Function Calling](#function-calling)
    
*   [Group multiple generations into a single trace](#group-multiple-generations-into-a-single-trace)
    
*   [Update trace](#update-trace)
    
*   [Get started](#get-started)
    

[Question? Give us feedback → (opens in a new tab)](https://github.com/langfuse/langfuse-docs/issues/new?title=Feedback%20for%20%E2%80%9CCookbook%3A%20OpenAI%20Integration%20(JS%2FTS)%E2%80%9D&labels=feedback)
[Edit this page on GitHub](https://github.com/langfuse/langfuse-docs/tree/main/pages/docs/integrations/openai/js/examples.md)
Scroll to top

Docs

Integrations

OpenAI SDK

JS/TS

Example Notebook

This is a Jupyter notebook

[Open on GitHub](https://github.com/langfuse/langfuse-docs/blob/main/cookbook/js_integration_openai.ipynb)
[Run on Google Colab](https://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/cookbook/js_integration_openai.ipynb)

Cookbook: OpenAI Integration (JS/TS)
====================================

This cookbook provides examples of the Langfuse Integration for OpenAI (JS/TS). Follow the [integration guide (opens in a new tab)](https://langfuse.com/docs/integrations/openai/js/get-started)
 to add this integration to your OpenAI project.

Setup[](#setup)

----------------

The integration is compatible with OpenAI SDK versions >=4.0.0.

_Note: This cookbook uses Deno.js, which requires different syntax for importing packages and setting environment variables._

    import OpenAI from "npm:openai@^4.0.0";
    import { observeOpenAI } from "npm:langfuse@^3.6.0";

You can set the secrets either via (1) environment variables or (2) initParams:

### 1\. Environment Variables[](#1-environment-variables)

    // Set env variables, Deno-specific syntax
    Deno.env.set("OPENAI_API_KEY", "");
    Deno.env.set("LANGFUSE_PUBLIC_KEY", "");
    Deno.env.set("LANGFUSE_SECRET_KEY", "");
    Deno.env.set("LANGFUSE_HOST", "https://cloud.langfuse.com") // For US data region, set this to "https://us.cloud.langfuse.com"

    // Initialize OpenAI client with observerOpenAI wrapper
    const openai = observeOpenAI(new OpenAI());

### 2\. InitParams[](#2-initparams)

    import OpenAI from "npm:openai";
    import { observeOpenAI } from "npm:langfuse";
     
    const openai = observeOpenAI(new OpenAI({apiKey: ""}), 
         {clientInitParams: {
            publicKey: "",
            secretKey: "",
            baseUrl: "https://cloud.langfuse.com", // Your host, defaults to https://cloud.langfuse.com
            // For US data region, set this to "https://us.cloud.langfuse.com"
          }});

Examples[](#examples)

----------------------

### Chat completion[](#chat-completion)

    import OpenAI from "npm:openai";
    import { observeOpenAI } from "npm:langfuse";
     
    // Configured via environment variables, see above
    const openai = observeOpenAI(new OpenAI());
     
    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: "system", content: "Tell me a joke." }],
      max_tokens: 100,
    });
     
    // notebook only: await events being flushed to Langfuse
    await openai.flushAsync();
     
    console.log(completion.choices[0]?.message.content);

Public trace: [https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/c4d32379-749f-460e-ad88-a95f0820c855 (opens in a new tab)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/c4d32379-749f-460e-ad88-a95f0820c855)

![Langfuse Trace](https://langfuse.com/images/cookbook/js_integration_openai_simple.png)

### Chat completion (streaming)[](#chat-completion-streaming)

Simple example using OpenAI streaming, passing custom parameters to rename the generation and add a tag to the trace.

    import OpenAI from "npm:openai";
    import { observeOpenAI } from "npm:langfuse";
     
    // Initialize OpenAI SDK with Langfuse
    const openaiWithLangfuse = observeOpenAI(new OpenAI(), { generationName: "OpenAI Stream Trace", tags: ["stream"]} )
     
    // Call OpenAI
    const stream = await openaiWithLangfuse.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: "system", content: "Tell me a joke." }],
      stream: true,
    });
     
    for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        console.log(content);
      }
     
    // notebook only: await events being flushed to Langfuse
    await openaiWithLangfuse.flushAsync();

Public trace: [https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/7c7acc02-6129-448b-84d3-5973e0256175 (opens in a new tab)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/7c7acc02-6129-448b-84d3-5973e0256175)

### Add additional metadata and parameters[](#add-additional-metadata-and-parameters)

The trace is a core object in Langfuse, and you can add rich metadata to it. Refer to the JS/TS SDK documentation and the [reference (opens in a new tab)](https://js.reference.langfuse.com/functions/langfuse.observeOpenAI.html)
 for comprehensive details.

Example usage:

*   Assigning a custom name to identify a specific trace type
*   Enabling user-level tracking
*   Tracking experiments through versions and releases
*   Adding custom metadata

    import OpenAI from "npm:openai";
    import { observeOpenAI } from "npm:langfuse";
     
    // Initialize OpenAI SDK with Langfuse and custom parameters
    const openaiWithLangfuse = observeOpenAI(new OpenAI(), {
        generationName: "OpenAI Custom Trace",
        metadata: {env: "dev"},
        sessionId: "session-id",
        userId: "user-id",
        tags: ["custom"],
        version: "0.0.1",
        release: "beta",
    })
     
    // Call OpenAI
    const completion = await openaiWithLangfuse.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: "system", content: "Tell me a joke." }],
      max_tokens: 100,
    });
     
    // notebook only: await events being flushed to Langfuse
    await openaiWithLangfuse.flushAsync();

Public trace: [https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/8c7ac9d0-ae3d-43cd-a69b-ef8ce888fd4a (opens in a new tab)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/8c7ac9d0-ae3d-43cd-a69b-ef8ce888fd4a)

### Function Calling[](#function-calling)

    import OpenAI from "npm:openai";
    import { observeOpenAI } from "npm:langfuse";
     
    // Initialize OpenAI SDK with Langfuse
    const openaiWithLangfuse = observeOpenAI(new OpenAI(), { generationName: "OpenAI FunctionCall Trace", tags: ["function"]} )
     
    // Define custom function
    async function getWeather(location: string) {
      if (location === "Berlin")
        {return "20degC"}
      else 
        {return "unknown"}
    }
     
    // Create function specification required for OpenAI API
    const functions = [{\
        type: "function",\
        function: {\
            name: "getWeather",\
            description: "Get the current weather in a given location",\
            parameters: {\
                type: "object",\
                properties: {\
                    location: {\
                        type: "string",\
                        description: "The city, e.g. San Francisco",\
                    },\
                },\
                required: ["location"],\
            },\
        },\
    }]
     
    // Call OpenAI
    const res = await openaiWithLangfuse.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: "What's the weather like in Berlin today"}],
        tool_choice: "auto",
        tools: functions,
    })
     
    const tool_call = res.choices[0].message.tool_calls;
    if (tool_call[0].function.name === "getWeather") {
        const argsStr = tool_call[0].function.arguments;
        const args = JSON.parse(argsStr); 
        const answer = await getWeather(args["location"]);
        console.log(answer);
    }
     
    // notebook only: await events being flushed to Langfuse
    await openaiWithLangfuse.flushAsync();

Public trace: [https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/ef0a2a2c-e9b5-44cf-b984-4b184dc711a7 (opens in a new tab)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/ef0a2a2c-e9b5-44cf-b984-4b184dc711a7)

### Group multiple generations into a single trace[](#group-multiple-generations-into-a-single-trace)

Use the Langfuse JS/TS SDK to create traces or spans and add OpenAI calls to it by passing the trace/span as a `parent` to the `observeOpenAI` wrapper.

    import Langfuse from "npm:langfuse";
    import { observeOpenAI } from "npm:langfuse";
    import OpenAI from "npm:openai";
     
     
    // Init Langfuse SDK
    const langfuse = new Langfuse();
     
    // Create trace and add params
    const trace = langfuse.trace({ name: "capital-poem-generator", tags: ["grouped"]});
     
    // Create span
    const country = "Germany";
    const span = trace.span({ name: country });
     
    // Call OpenAI
    const capital = (
      await observeOpenAI(new OpenAI(), {
        parent: span,
        generationName: "get-capital",
      }).chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [\
          { role: "system", content: "What is the capital of the country?" },\
          { role: "user", content: country },\
        ],
      })
    ).choices[0].message.content;
     
    const poem = (
      await observeOpenAI(new OpenAI(), {
        parent: span,
        generationName: "generate-poem",
      }).chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [\
          {\
            role: "system",\
            content: "You are a poet. Create a poem about this city.",\
          },\
          { role: "user", content: capital },\
        ],
      })
    ).choices[0].message.content;
     
    // End span to get span-level latencies
    span.end();
     
    // notebook only: await events being flushed to Langfuse
    await langfuse.flushAsync();

Public trace: [https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/02e76ecc-b233-4617-bc29-67538ea1a41c (opens in a new tab)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/02e76ecc-b233-4617-bc29-67538ea1a41c)

![Langfuse Trace](https://langfuse.com/images/cookbook/js_integration_openai_grouped.png)

### Update trace[](#update-trace)

    import Langfuse from "npm:langfuse";
    import { observeOpenAI } from "npm:langfuse";
    import OpenAI from "npm:openai";
     
    // Init Langfuse SDK
    const langfuse = new Langfuse();
     
    // Create trace and add params
    const trace = langfuse.trace({ name: "capital-poem-generator" });
     
    // Create span
    const span = trace.span({ name: "France" });
     
    const capital = (
      await observeOpenAI(new OpenAI(), {
        parent: span,
        generationName: "get-capital",
      }).chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [\
          { role: "system", content: "What is the capital of the country?" },\
          { role: "user", content: "France" },\
        ],
      })
    ).choices[0].message.content;
     
    const poem = (
      await observeOpenAI(new OpenAI(), {
        parent: span,
        generationName: "generate-poem",
      }).chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [\
          {\
            role: "system",\
            content: "You are a poet. Create a poem about this city.",\
          },\
          { role: "user", content: capital },\
        ],
      })
    ).choices[0].message.content;
     
    // Update span to get IO on span-level
    span.update({input: capital, output: poem});
     
    // End span to get span-level latencies
    span.end();
     
    // Update trace
    trace.update({
        name:"City poem generator",
        tags: ["updated"],
        metadata: {"env": "development"},
        release: "v0.0.2",
        output: poem,
    });
     
    // notebook only: await events being flushed to Langfuse
    await langfuse.flushAsync();

Public trace: [https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/4a40e120-348f-4c22-bf16-453d5486f47a (opens in a new tab)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/4a40e120-348f-4c22-bf16-453d5486f47a)

Get started[](#get-started)

----------------------------

Follow the [integration guide (opens in a new tab)](https://langfuse.com/docs/integrations/openai/js/get-started)
 to add this integration to your OpenAI project.

[Get Started](/docs/integrations/openai/js/get-started "Get Started")
[Tracing](/docs/integrations/langchain/tracing "Tracing")

### Was this page useful?

YesCould be better

### Questions? We're here to help

[GitHub Q&AGitHub](/gh-support)
Chat [Email](/cdn-cgi/l/email-protection#21525451514e5355614d404f46475452440f424e4c)
[Talk to sales](/schedule-demo)

### Subscribe to updates

Get updates

Light

* * *

Platform

*   [LLM Tracing](/docs/tracing)
    
*   [Prompt Management](/docs/prompts/get-started)
    
*   [Evaluation](/docs/scores/overview)
    
*   [Manual Annotation](/docs/scores/annotation)
    
*   [Datasets](/docs/datasets/overview)
    
*   [Metrics](/docs/analytics)
    
*   [Playground](/docs/playground)
    

Integrations

*   [Python SDK](/docs/sdk/python)
    
*   [JS/TS SDK](/docs/sdk/typescript/guide)
    
*   [OpenAI SDK](/docs/integrations/openai/get-started)
    
*   [Langchain](/docs/integrations/langchain/tracing)
    
*   [Llama-Index](/docs/integrations/llama-index/get-started)
    
*   [Litellm](/docs/integrations/litellm)
    
*   [Dify](/docs/integrations/dify)
    
*   [Flowise](/docs/integrations/flowise)
    
*   [Langflow](/docs/integrations/langflow)
    
*   [Vercel AI SDK](/docs/sdk/typescript/example-vercel-ai)
    
*   [Instructor](/docs/integrations/instructor)
    
*   [Mirascope](/docs/integrations/mirascope)
    
*   [API](https://api.reference.langfuse.com/)
    

Resources

*   [Documentation](/docs)
    
*   [Interactive Demo](/demo)
    
*   [Video demo (3 min)](/video)
    
*   [Changelog](/changelog)
    
*   [Roadmap](/docs/roadmap)
    
*   [Pricing](/pricing)
    
*   [Enterprise](/enterprise)
    
*   [Self-hosting](/docs/deployment/self-host)
    
*   [Open Source](/docs/open-source)
    
*   [Why Langfuse?](/why)
    
*   [Status](https://status.langfuse.com)
    

About

*   [Blog](/blog)
    
*   [Careers](/careers)
    3
*   [About us](/about)
    
*   [Support](/support)
    
*   [Schedule Demo](/schedule-demo)
    
*   [OSS Friends](/oss-friends)
    

Legal

*   [Security](/security)
    
*   [Imprint](/imprint)
    
*   [Terms](/terms)
    
*   [Privacy](/privacy)
    

© 2022-2024 Langfuse GmbH / Finto Technologies Inc.