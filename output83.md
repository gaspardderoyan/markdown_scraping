---
domain: langfuse.com
path: /docs/prompts/example-langchain
url: https://langfuse.com/docs/prompts/example-langchain
---

[Join us in Engineering & DevRel →We're hiring. Join us in Product Eng, Backend Eng, and DevRel →](/careers)

[![Langfuse Logo](https://langfuse.com/langfuse_logo_white.svg)![Langfuse Logo](https://langfuse.com/langfuse_logo.svg)](/)
[DocsDocs](/docs)
[PricingPricing](/pricing)
[ChangelogChangelog](/changelog)
[BlogBlog](/blog)

Demo

[Discord](https://discord.langfuse.com)
[](https://x.com/langfuse)
[GitHub](https://github.com/langfuse/langfuse "GitHub Repository")
[Sign Up](https://cloud.langfuse.com)

*   Docs
    
    [Guides](/guides)
    [FAQ](/faq)
    
*   [Overview](/docs)
    
*   [Interactive Demo](/docs/demo)
    
*   Self-host
    
    *   [Local (docker compose)](/docs/deployment/local)
        
    *   [Self-host (docker)](/docs/deployment/self-host)
        
    
*   Tracing
*   [Introduction](/docs/tracing)
    
*   [Quickstart](/docs/get-started)
    
*   Features
    
    *   [Sessions](/docs/tracing-features/sessions)
        
    *   [Users](/docs/tracing-features/users)
        
    *   [Metadata](/docs/tracing-features/metadata)
        
    *   [Tags](/docs/tracing-features/tags)
        
    *   [Trace URL](/docs/tracing-features/url)
        
    *   [Log Levels](/docs/tracing-features/log-levels)
        
    *   [Sampling](/docs/tracing-features/sampling)
        
    
*   SDKs
    
    *   [Overview](/docs/sdk/overview)
        
    *   Python
        
        *   [Decorators](/docs/sdk/python/decorators)
            
        *   [Example Notebook](/docs/sdk/python/example)
            
        *   [Low-level SDK](/docs/sdk/python/low-level-sdk)
            
        *   [Reference ↗ (opens in a new tab)](https://python.reference.langfuse.com)
            
        
    *   JS/TS
        
        *   [Guide](/docs/sdk/typescript/guide)
            
        *   [Guide (Web)](/docs/sdk/typescript/guide-web)
            
        *   [Example (Vercel AI)](/docs/sdk/typescript/example-vercel-ai)
            
        *   [Reference ↗ (opens in a new tab)](https://js.reference.langfuse.com)
            
        
    
*   Integrations
    
    *   [Overview](/docs/integrations/overview)
        
    *   OpenAI SDK
        
        *   Python
            
            *   [Get Started](/docs/integrations/openai/python/get-started)
                
            *   [Track Errors](/docs/integrations/openai/python/track-errors)
                
            *   [Example Notebook](/docs/integrations/openai/python/examples)
                
            *   [Assistants API](/docs/integrations/openai/python/assistants-api)
                
            *   [Structured Outputs](/docs/integrations/openai/python/structured-outputs)
                
            
        *   JS/TS
            
            *   [Get Started](/docs/integrations/openai/js/get-started)
                
            *   [Example Notebook](/docs/integrations/openai/js/examples)
                
            
        
    *   Langchain
        
        *   [Tracing](/docs/integrations/langchain/tracing)
            
        *   [Example Python](/docs/integrations/langchain/example-python)
            
        *   [Example JS](/docs/integrations/langchain/example-javascript)
            
        *   [Example LangGraph](/docs/integrations/langchain/example-python-langgraph)
            
        *   [Example LangServe](/docs/integrations/langchain/example-python-langserve)
            
        *   [Upgrade Paths](/docs/integrations/langchain/upgrade-paths)
            
        
    *   LlamaIndex
        
        *   [Get Started](/docs/integrations/llama-index/get-started)
            
        *   [Example (Python)](/docs/integrations/llama-index/example-python)
            
        
    *   Haystack
        
        *   [Get Started](/docs/integrations/haystack/get-started)
            
        *   [Example (Python)](/docs/integrations/haystack/example-python)
            
        
    *   LiteLLM
        
        *   [Tracing](/docs/integrations/litellm/tracing)
            
        *   [Example Proxy (Python)](/docs/integrations/litellm/example-proxy-python)
            
        *   [Example Proxy (JS/TS)](/docs/integrations/litellm/example-proxy-js)
            
        
    *   [Vercel AI SDK](/docs/integrations/vercel-ai-sdk)
        
    *   [Dify.AI](/docs/integrations/dify)
        
    *   [Instructor](/docs/integrations/instructor)
        
    *   Mirascope
        
        *   [Tracing](/docs/integrations/mirascope/tracing)
            
        *   [Example Notebook](/docs/integrations/mirascope/example-python)
            
        
    *   [Flowise](/docs/integrations/flowise)
        
    *   [Langflow](/docs/integrations/langflow)
        
    
*   [Query Traces](/docs/query-traces)
    
*   Develop
*   Prompt Management
    
    *   [Get Started](/docs/prompts/get-started)
        
    *   [Example OpenAI Functions](/docs/prompts/example-openai-functions)
        
    *   [Example Langchain (Py)](/docs/prompts/example-langchain)
        
    *   [Example Langchain (JS)](/docs/prompts/example-langchain-js)
        
    
*   [Playground](/docs/playground)
    
*   [Fine-tuning](/docs/fine-tuning)
    
*   Monitor
*   Analytics
    
    *   [Overview](/docs/analytics/overview)
        
    *   [PostHog Integration](/docs/analytics/posthog)
        
    *   [Daily Metrics API](/docs/analytics/daily-metrics-api)
        
    
*   [Model Usage & Cost](/docs/model-usage-and-cost)
    
*   Scores & Evaluation
    
    *   [Overview](/docs/scores/overview)
        
    *   [Annotation in UI](/docs/scores/annotation)
        
    *   [User Feedback](/docs/scores/user-feedback)
        
    *   [Model-based Evaluation](/docs/scores/model-based-evals)
        
    *   [Custom via SDKs/API](/docs/scores/custom)
        
    
*   LLM Security
    
    *   [Overview](/docs/security/overview)
        
    *   [Example Python](/docs/security/example-python)
        
    
*   Test
*   [Experimentation](/docs/experimentation)
    
*   Datasets
    
    *   [Overview](/docs/datasets/overview)
        
    *   [Cookbook](/docs/datasets/python-cookbook)
        
    
*   References
*   [API ↗ (opens in a new tab)](https://api.reference.langfuse.com)
    
*   [Python SDK ↗ (opens in a new tab)](https://python.reference.langfuse.com)
    
*   [JS SDK ↗ (opens in a new tab)](https://js.reference.langfuse.com)
    
*   More
*   [Access Control (RBAC)](/docs/rbac)
    
*   [Data Security & Privacy](/docs/data-security-privacy)
    
*   [Open Source](/docs/open-source)
    
*   [Roadmap](/docs/roadmap)
    
*   [Support ↗ (opens in a new tab)](/support)
    

Light

On This Page

*   [Setup](#setup)
    
*   [Add prompt to Langfuse Prompt Management](#add-prompt-to-langfuse-prompt-management)
    
*   [Example application](#example-application)
    
*   [Get current prompt version from Langfuse](#get-current-prompt-version-from-langfuse)
    
*   [Transform into Langchain PromptTemplate](#transform-into-langchain-prompttemplate)
    
*   [Create Langchain chain based on prompt](#create-langchain-chain-based-on-prompt)
    
*   [Invoke chain](#invoke-chain)
    
*   [View Trace in Langfuse](#view-trace-in-langfuse)
    
*   [Iterate on prompt in Langfuse](#iterate-on-prompt-in-langfuse)
    

[Question? Give us feedback → (opens in a new tab)](https://github.com/langfuse/langfuse-docs/issues/new?title=Feedback%20for%20%E2%80%9CExample%3A%20Langfuse%20Prompt%20Management%20with%20Langchain%20(Python)%E2%80%9D&labels=feedback)
[Edit this page on GitHub](https://github.com/langfuse/langfuse-docs/tree/main/pages/docs/prompts/example-langchain.md)
Scroll to top

Docs

Prompt Management

Example Langchain (Py)

This is a Jupyter notebook

[Open on GitHub](https://github.com/langfuse/langfuse-docs/blob/main/cookbook/prompt_management_langchain.ipynb)
[Run on Google Colab](https://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/cookbook/prompt_management_langchain.ipynb)

Example: Langfuse Prompt Management with Langchain (Python)
===========================================================

[Langfuse Prompt Management (opens in a new tab)](https://langfuse.com/docs/prompts)
 helps to version control and manage prompts collaboratively in one place. This example demostrates how to use prompts managed in Langchain applications.

_In addition, we use [Langfuse Tracing (opens in a new tab)](https://langfuse.com/docs/tracing)
 via the native [Langchain integration (opens in a new tab)](https://langfuse.com/docs/integrations/langchain)
 to inspect and debug the Langchain application._

Setup[](#setup)

----------------

    %pip install langfuse langchain langchain-openai --upgrade

    import os
     
    # get keys for your project from https://cloud.langfuse.com
    os.environ["LANGFUSE_PUBLIC_KEY"] = ""
    os.environ["LANGFUSE_SECRET_KEY"] = ""
    os.environ["LANGFUSE_HOST"] = "https://cloud.langfuse.com"
     
    # your openai key
    os.environ["OPENAI_API_KEY"] = ""

    from langfuse import Langfuse
    from langfuse.callback import CallbackHandler
     
    # Initialize Langfuse client (prompt management)
    langfuse = Langfuse()
     
    # Initialize Langfuse CallbackHandler for Langchain (tracing)
    langfuse_callback_handler = CallbackHandler()
     
    # Optional, verify that Langfuse is configured correctly
    assert langfuse.auth_check()
    assert langfuse_callback_handler.auth_check()

Add prompt to Langfuse Prompt Management[](#add-prompt-to-langfuse-prompt-management)

--------------------------------------------------------------------------------------

We add the prompt used in this example via the SDK. Alternatively, you can also edit and version the prompt in the Langfuse UI.

*   `Name` that identifies the prompt in Langfuse Prompt Management
*   Prompt with prompt template incl. `{{input variables}}`
*   Config including `model_name` and `temperature`
*   `labels` to include `production` to immediately use prompt as the default

    langfuse.create_prompt(
        name="event-planner",
        prompt=
        "Plan an event titled {{Event Name}}. The event will be about: {{Event Description}}. "
        "The event will be held in {{Location}} on {{Date}}. "
        "Consider the following factors: audience, budget, venue, catering options, and entertainment. "
        "Provide a detailed plan including potential vendors and logistics.",
        config={
            "model":"gpt-3.5-turbo-1106",
            "temperature": 0,
        },
        labels=["production"]
    );

Prompt in Langfuse UI

![Created prompt in Langfuse UI](https://langfuse.com/images/docs/prompt-management-langchain-prompt.png)

Example application[](#example-application)

--------------------------------------------

### Get current prompt version from Langfuse[](#get-current-prompt-version-from-langfuse)

    # Get current production version of prompt
    langfuse_prompt = langfuse.get_prompt("event-planner")

    print(langfuse_prompt.prompt)

    Plan an event titled {{Event Name}}. The event will be about: {{Event Description}}. The event will be held in {{Location}} on {{Date}}. Consider the following factors: audience, budget, venue, catering options, and entertainment. Provide a detailed plan including potential vendors and logistics.

### Transform into Langchain PromptTemplate[](#transform-into-langchain-prompttemplate)

Use the utility method `.get_langchain_prompt()` to transform the Langfuse prompt into a string that can be used in Langchain.

Context: Langfuse declares input variables in prompt templates using double brackets (`{{input variable}}`). Langchain uses single brackets for declaring input variables in PromptTemplates (`{input variable}`). The utility method `.get_langchain_prompt()` replaces the double brackets with single brackets.

    from langchain_core.prompts import ChatPromptTemplate
     
    langchain_prompt = ChatPromptTemplate.from_template(langfuse_prompt.get_langchain_prompt())

Extract the configuration options from `prompt.config`

    model = langfuse_prompt.config["model"]
    temperature = str(langfuse_prompt.config["temperature"])
    print(f"Prompt model configurations\nModel: {model}\nTemperature: {temperature}")

    Prompt model configurations
    Model: gpt-3.5-turbo-1106
    Temperature: 0

### Create Langchain chain based on prompt[](#create-langchain-chain-based-on-prompt)

    from langchain_openai import ChatOpenAI
     
    model = ChatOpenAI(model=model, temperature=temperature)
     
    chain = langchain_prompt | model

Invoke chain[](#invoke-chain)

------------------------------

    example_input = {
        "Event Name": "Wedding",
        "Event Description": "The wedding of Julia and Alex, a charming couple who share a love for art and nature. This special day will celebrate their journey together with a blend of traditional and contemporary elements, reflecting their unique personalities.",
        "Location": "Central Park, New York City",
        "Date": "June 5, 2024"
    }

    # we pass the callback handler to the chain to trace the run in Langfuse
    response = chain.invoke(input=example_input,config={"callbacks":[langfuse_callback_handler]})
     
    print(response.content)

    Event Title: Julia and Alex's Artful Nature Wedding
    
    Audience: Family, friends, and loved ones of Julia and Alex, as well as art and nature enthusiasts.
    
    Budget: $30,000
    
    Venue: Central Park, New York City
    
    Catering Options: 
    - Organic and locally sourced menu options
    - Vegetarian and vegan options
    - Artfully presented dishes
    - Champagne toast and signature cocktails
    
    Entertainment:
    - Live acoustic music during the ceremony
    - DJ for the reception
    - Interactive art stations for guests to create their own masterpieces
    - Nature-inspired photo booth
    
    Logistics:
    - Ceremony and reception to be held in a secluded area of Central Park, surrounded by lush greenery and blooming flowers
    - Tents and seating to be set up for guests
    - Art installations and sculptures to be placed around the venue
    - Transportation for guests to and from the park
    - Permits and permissions for the event in Central Park
    
    Potential Vendors:
    - Catering: Farm-to-table catering company
    - Music: Local acoustic musician and DJ
    - Art installations: Local artists and galleries
    - Photography: Nature and art-focused photographer
    - Transportation: Eco-friendly shuttle service
    
    Overall, the wedding will be a beautiful blend of art and nature, with a focus on sustainability and creativity. The event will showcase the couple's love for each other and their shared passions, creating a memorable and unique experience for all in attendance.

View Trace in Langfuse[](#view-trace-in-langfuse)

--------------------------------------------------

Now we can see that the trace incl. the prompt template have been logged to Langfuse

![Trace of prompt used in Langchain in Langfuse](https://langfuse.com/images/docs/prompt-management-langchain-trace.png)

Iterate on prompt in Langfuse[](#iterate-on-prompt-in-langfuse)

----------------------------------------------------------------

We can now continue adapting our prompt template in the Langfuse UI and continuously update the prompt template in our Langchain application via the script above.

[Example OpenAI Functions](/docs/prompts/example-openai-functions "Example OpenAI Functions")
[Example Langchain (JS)](/docs/prompts/example-langchain-js "Example Langchain (JS)")

### Was this page useful?

YesCould be better

### Questions? We're here to help

[GitHub Q&AGitHub](/gh-support)
Chat [Email](/cdn-cgi/l/email-protection#1b686e6b6b74696f5b777a757c7d6e687e35787476)
[Talk to sales](/schedule-demo)

### Subscribe to updates

Get updates

Light

* * *

Platform

*   [LLM Tracing](/docs/tracing)
    
*   [Prompt Management](/docs/prompts/get-started)
    
*   [Evaluation](/docs/scores/overview)
    
*   [Manual Annotation](/docs/scores/annotation)
    
*   [Datasets](/docs/datasets/overview)
    
*   [Metrics](/docs/analytics)
    
*   [Playground](/docs/playground)
    

Integrations

*   [Python SDK](/docs/sdk/python)
    
*   [JS/TS SDK](/docs/sdk/typescript/guide)
    
*   [OpenAI SDK](/docs/integrations/openai/get-started)
    
*   [Langchain](/docs/integrations/langchain/tracing)
    
*   [Llama-Index](/docs/integrations/llama-index/get-started)
    
*   [Litellm](/docs/integrations/litellm)
    
*   [Dify](/docs/integrations/dify)
    
*   [Flowise](/docs/integrations/flowise)
    
*   [Langflow](/docs/integrations/langflow)
    
*   [Vercel AI SDK](/docs/sdk/typescript/example-vercel-ai)
    
*   [Instructor](/docs/integrations/instructor)
    
*   [Mirascope](/docs/integrations/mirascope)
    
*   [API](https://api.reference.langfuse.com/)
    

Resources

*   [Documentation](/docs)
    
*   [Interactive Demo](/demo)
    
*   [Video demo (3 min)](/video)
    
*   [Changelog](/changelog)
    
*   [Roadmap](/docs/roadmap)
    
*   [Pricing](/pricing)
    
*   [Enterprise](/enterprise)
    
*   [Self-hosting](/docs/deployment/self-host)
    
*   [Open Source](/docs/open-source)
    
*   [Why Langfuse?](/why)
    
*   [Status](https://status.langfuse.com)
    

About

*   [Blog](/blog)
    
*   [Careers](/careers)
    3
*   [About us](/about)
    
*   [Support](/support)
    
*   [Schedule Demo](/schedule-demo)
    
*   [OSS Friends](/oss-friends)
    

Legal

*   [Security](/security)
    
*   [Imprint](/imprint)
    
*   [Terms](/terms)
    
*   [Privacy](/privacy)
    

© 2022-2024 Langfuse GmbH / Finto Technologies Inc.