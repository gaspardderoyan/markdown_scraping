---
domain: langfuse.com
path: /docs/datasets/python-cookbook
url: https://langfuse.com/docs/datasets/python-cookbook
---

[Join us in Engineering & DevRel →We're hiring. Join us in Product Eng, Backend Eng, and DevRel →](/careers)

[![Langfuse Logo](https://langfuse.com/langfuse_logo_white.svg)![Langfuse Logo](https://langfuse.com/langfuse_logo.svg)](/)
[DocsDocs](/docs)
[PricingPricing](/pricing)
[ChangelogChangelog](/changelog)
[BlogBlog](/blog)

Demo

[Discord](https://discord.langfuse.com)
[](https://x.com/langfuse)
[GitHub](https://github.com/langfuse/langfuse "GitHub Repository")
[Sign Up](https://cloud.langfuse.com)

*   Docs
    
    [Guides](/guides)
    [FAQ](/faq)
    
*   [Overview](/docs)
    
*   [Interactive Demo](/docs/demo)
    
*   Self-host
    
    *   [Local (docker compose)](/docs/deployment/local)
        
    *   [Self-host (docker)](/docs/deployment/self-host)
        
    
*   Tracing
*   [Introduction](/docs/tracing)
    
*   [Quickstart](/docs/get-started)
    
*   Features
    
    *   [Sessions](/docs/tracing-features/sessions)
        
    *   [Users](/docs/tracing-features/users)
        
    *   [Metadata](/docs/tracing-features/metadata)
        
    *   [Tags](/docs/tracing-features/tags)
        
    *   [Trace URL](/docs/tracing-features/url)
        
    *   [Log Levels](/docs/tracing-features/log-levels)
        
    *   [Sampling](/docs/tracing-features/sampling)
        
    
*   SDKs
    
    *   [Overview](/docs/sdk/overview)
        
    *   Python
        
        *   [Decorators](/docs/sdk/python/decorators)
            
        *   [Example Notebook](/docs/sdk/python/example)
            
        *   [Low-level SDK](/docs/sdk/python/low-level-sdk)
            
        *   [Reference ↗ (opens in a new tab)](https://python.reference.langfuse.com)
            
        
    *   JS/TS
        
        *   [Guide](/docs/sdk/typescript/guide)
            
        *   [Guide (Web)](/docs/sdk/typescript/guide-web)
            
        *   [Example (Vercel AI)](/docs/sdk/typescript/example-vercel-ai)
            
        *   [Reference ↗ (opens in a new tab)](https://js.reference.langfuse.com)
            
        
    
*   Integrations
    
    *   [Overview](/docs/integrations/overview)
        
    *   OpenAI SDK
        
        *   Python
            
            *   [Get Started](/docs/integrations/openai/python/get-started)
                
            *   [Track Errors](/docs/integrations/openai/python/track-errors)
                
            *   [Example Notebook](/docs/integrations/openai/python/examples)
                
            *   [Assistants API](/docs/integrations/openai/python/assistants-api)
                
            *   [Structured Outputs](/docs/integrations/openai/python/structured-outputs)
                
            
        *   JS/TS
            
            *   [Get Started](/docs/integrations/openai/js/get-started)
                
            *   [Example Notebook](/docs/integrations/openai/js/examples)
                
            
        
    *   Langchain
        
        *   [Tracing](/docs/integrations/langchain/tracing)
            
        *   [Example Python](/docs/integrations/langchain/example-python)
            
        *   [Example JS](/docs/integrations/langchain/example-javascript)
            
        *   [Example LangGraph](/docs/integrations/langchain/example-python-langgraph)
            
        *   [Example LangServe](/docs/integrations/langchain/example-python-langserve)
            
        *   [Upgrade Paths](/docs/integrations/langchain/upgrade-paths)
            
        
    *   LlamaIndex
        
        *   [Get Started](/docs/integrations/llama-index/get-started)
            
        *   [Example (Python)](/docs/integrations/llama-index/example-python)
            
        
    *   Haystack
        
        *   [Get Started](/docs/integrations/haystack/get-started)
            
        *   [Example (Python)](/docs/integrations/haystack/example-python)
            
        
    *   LiteLLM
        
        *   [Tracing](/docs/integrations/litellm/tracing)
            
        *   [Example Proxy (Python)](/docs/integrations/litellm/example-proxy-python)
            
        *   [Example Proxy (JS/TS)](/docs/integrations/litellm/example-proxy-js)
            
        
    *   [Vercel AI SDK](/docs/integrations/vercel-ai-sdk)
        
    *   [Dify.AI](/docs/integrations/dify)
        
    *   [Instructor](/docs/integrations/instructor)
        
    *   Mirascope
        
        *   [Tracing](/docs/integrations/mirascope/tracing)
            
        *   [Example Notebook](/docs/integrations/mirascope/example-python)
            
        
    *   [Flowise](/docs/integrations/flowise)
        
    *   [Langflow](/docs/integrations/langflow)
        
    
*   [Query Traces](/docs/query-traces)
    
*   Develop
*   Prompt Management
    
    *   [Get Started](/docs/prompts/get-started)
        
    *   [Example OpenAI Functions](/docs/prompts/example-openai-functions)
        
    *   [Example Langchain (Py)](/docs/prompts/example-langchain)
        
    *   [Example Langchain (JS)](/docs/prompts/example-langchain-js)
        
    
*   [Playground](/docs/playground)
    
*   [Fine-tuning](/docs/fine-tuning)
    
*   Monitor
*   Analytics
    
    *   [Overview](/docs/analytics/overview)
        
    *   [PostHog Integration](/docs/analytics/posthog)
        
    *   [Daily Metrics API](/docs/analytics/daily-metrics-api)
        
    
*   [Model Usage & Cost](/docs/model-usage-and-cost)
    
*   Scores & Evaluation
    
    *   [Overview](/docs/scores/overview)
        
    *   [Annotation in UI](/docs/scores/annotation)
        
    *   [User Feedback](/docs/scores/user-feedback)
        
    *   [Model-based Evaluation](/docs/scores/model-based-evals)
        
    *   [Custom via SDKs/API](/docs/scores/custom)
        
    
*   LLM Security
    
    *   [Overview](/docs/security/overview)
        
    *   [Example Python](/docs/security/example-python)
        
    
*   Test
*   [Experimentation](/docs/experimentation)
    
*   Datasets
    
    *   [Overview](/docs/datasets/overview)
        
    *   [Cookbook](/docs/datasets/python-cookbook)
        
    
*   References
*   [API ↗ (opens in a new tab)](https://api.reference.langfuse.com)
    
*   [Python SDK ↗ (opens in a new tab)](https://python.reference.langfuse.com)
    
*   [JS SDK ↗ (opens in a new tab)](https://js.reference.langfuse.com)
    
*   More
*   [Access Control (RBAC)](/docs/rbac)
    
*   [Data Security & Privacy](/docs/data-security-privacy)
    
*   [Open Source](/docs/open-source)
    
*   [Roadmap](/docs/roadmap)
    
*   [Support ↗ (opens in a new tab)](/support)
    

Light

On This Page

*   [Setup](#setup)
    
*   [Create a dataset](#create-a-dataset)
    
*   [Items](#items)
    
*   [Define application and run experiments](#define-application-and-run-experiments)
    
*   [Custom app](#custom-app)
    
*   [Langchain application](#langchain-application)
    
*   [Evaluate experiments in Langfuse UI](#evaluate-experiments-in-langfuse-ui)
    

[Question? Give us feedback → (opens in a new tab)](https://github.com/langfuse/langfuse-docs/issues/new?title=Feedback%20for%20%E2%80%9CLangfuse%20Datasets%20Cookbook%E2%80%9D&labels=feedback)
[Edit this page on GitHub](https://github.com/langfuse/langfuse-docs/tree/main/pages/docs/datasets/python-cookbook.md)
Scroll to top

Docs

Datasets

Cookbook

This is a Jupyter notebook

[Open on GitHub](https://github.com/langfuse/langfuse-docs/blob/main/cookbook/datasets.ipynb)
[Run on Google Colab](https://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/cookbook/datasets.ipynb)

Langfuse Datasets Cookbook
==========================

In this cookbook, we'll iterate on systems prompts with the goal of getting only the capital of a given country. We use Langfuse datasets, to store a list of example inputs and expected outputs.

This is a very simple example, you can run experiments on any LLM application that you either trace with the [Langfuse SDKs (opens in a new tab)](https://langfuse.com/docs/sdk)
 (Python, JS/TS) or via one of our [integrations (opens in a new tab)](https://langfuse.com/docs/integrations)
 (e.g. Langchain).

_Simple example application_

*   **Model**: gpt-3.5-turbo
*   **Input**: country name
*   **Output**: capital
*   **Evaluation**: exact match of completion and ground truth
*   **Experiment on**: system prompt

Setup[](#setup)

----------------

    %pip install langfuse openai langchain_openai langchain --upgrade

    import os
     
    # get keys for your project from https://cloud.langfuse.com
    os.environ["LANGFUSE_PUBLIC_KEY"] = ""
    os.environ["LANGFUSE_SECRET_KEY"] = ""
     
    # your openai key
    os.environ["OPENAI_API_KEY"] = ""
     
    # Your host, defaults to https://cloud.langfuse.com
    # For US data region, set to "https://us.cloud.langfuse.com"
    # os.environ["LANGFUSE_HOST"] = "http://localhost:3000"

    # import
    from langfuse import Langfuse
    import openai
     
    # init
    langfuse = Langfuse()

Create a dataset[](#create-a-dataset)

--------------------------------------

    langfuse.create_dataset(name="capital_cities");

### Items[](#items)

Load local items into the Langfuse dataset. Alternatively you can add items from production via the Langfuse UI.

    # example items, could also be json instead of strings
    local_items = [\
        {"input": {"country": "Italy"}, "expected_output": "Rome"},\
        {"input": {"country": "Spain"}, "expected_output": "Madrid"},\
        {"input": {"country": "Brazil"}, "expected_output": "Brasília"},\
        {"input": {"country": "Japan"}, "expected_output": "Tokyo"},\
        {"input": {"country": "India"}, "expected_output": "New Delhi"},\
        {"input": {"country": "Canada"}, "expected_output": "Ottawa"},\
        {"input": {"country": "South Korea"}, "expected_output": "Seoul"},\
        {"input": {"country": "Argentina"}, "expected_output": "Buenos Aires"},\
        {"input": {"country": "South Africa"}, "expected_output": "Pretoria"},\
        {"input": {"country": "Egypt"}, "expected_output": "Cairo"},\
    ]

    # Upload to Langfuse
    for item in local_items:
      langfuse.create_dataset_item(
          dataset_name="capital_cities",
          # any python object or value
          input=item["input"],
          # any python object or value, optional
          expected_output=item["expected_output"]
    )

Define application and run experiments[](#define-application-and-run-experiments)

----------------------------------------------------------------------------------

We implement the application in two ways to demonstrate how it's done

1.  Custom LLM app using e.g. OpenAI SDK, traced with Langfuse Python SDK
2.  Langchain Application, traced via native Langfuse integration

    # we use a very simple eval here, you can use any eval library
    # see https://langfuse.com/docs/scores/model-based-evals for details
    def simple_evaluation(output, expected_output):
      return output == expected_output

### Custom app[](#custom-app)

    from datetime import datetime
     
    def run_my_custom_llm_app(input, system_prompt):
      messages = [\
          {"role":"system", "content": system_prompt},\
          {"role":"user", "content": input["country"]}\
      ]
     
      generationStartTime = datetime.now()
     
      openai_completion = openai.chat.completions.create(
          model="gpt-3.5-turbo",
          messages=messages
      ).choices[0].message.content
     
      langfuse_generation = langfuse.generation(
        name="guess-countries",
        input=messages,
        output=openai_completion,
        model="gpt-3.5-turbo",
        start_time=generationStartTime,
        end_time=datetime.now()
      )
     
      return openai_completion, langfuse_generation

    def run_experiment(experiment_name, system_prompt):
      dataset = langfuse.get_dataset("capital_cities")
     
      for item in dataset.items:
        completion, langfuse_generation = run_my_custom_llm_app(item.input, system_prompt)
     
        item.link(langfuse_generation, experiment_name) # pass the observation/generation object or the id
     
        langfuse_generation.score(
          name="exact_match",
          value=simple_evaluation(completion, item.expected_output)
        )

    run_experiment(
        "famous_city",
        "The user will input countries, respond with the most famous city in this country"
    )
    run_experiment(
        "directly_ask",
        "What is the capital of the following country?"
    )
    run_experiment(
        "asking_specifically",
        "The user will input countries, respond with only the name of the capital"
    )
    run_experiment(
        "asking_specifically_2nd_try",
        "The user will input countries, respond with only the name of the capital. State only the name of the city."
    )

### Langchain application[](#langchain-application)

    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate
    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
    from langchain_core.messages import HumanMessage
     
    def run_my_langchain_llm_app(input, system_message, callback_handler):
      prompt = ChatPromptTemplate.from_messages(
        [\
            (\
                "system",\
                system_message,\
            ),\
            MessagesPlaceholder(variable_name="messages"),\
        ]
      )
      chat = ChatOpenAI()
      chain = prompt | chat
     
      res = chain.invoke(
        { "messages": [HumanMessage(content=input)] },
        config={"callbacks":[callback_handler]}
      )
      
      return res

    def run_langchain_experiment(experiment_name, system_message):
      dataset = langfuse.get_dataset("capital_cities")
     
      for item in dataset.items:
        handler = item.get_langchain_handler(run_name=experiment_name)
     
        completion = run_my_langchain_llm_app(item.input["country"], system_message, handler)
     
        handler.trace.score(
          name="exact_match",
          value=simple_evaluation(completion, item.expected_output)
        )

    run_langchain_experiment(
        "langchain_famous_city",
        "The user will input countries, respond with the most famous city in this country"
    )
    run_langchain_experiment(
        "langchain_directly_ask",
        "What is the capital of the following country?"
    )
    run_langchain_experiment(
        "langchain_asking_specifically",
        "The user will input countries, respond with only the name of the capital"
    )
    run_langchain_experiment(
        "langchain_asking_specifically_2nd_try",
        "The user will input countries, respond with only the name of the capital. State only the name of the city."
    )

Evaluate experiments in Langfuse UI[](#evaluate-experiments-in-langfuse-ui)

----------------------------------------------------------------------------

*   Average scores per experiment run
*   Browse each run for an individual item
*   Look at traces to debug issues

![Experiment runs in Langfuse](https://langfuse.com/images/docs/dataset-runs-cookbook.jpg)

[Overview](/docs/datasets/overview "Overview")
API ↗

### Was this page useful?

YesCould be better

### Questions? We're here to help

[GitHub Q&AGitHub](/gh-support)
Chat [Email](/cdn-cgi/l/email-protection#42313732322d3036022e232c25243731276c212d2f)
[Talk to sales](/schedule-demo)

### Subscribe to updates

Get updates

Light

* * *

Platform

*   [LLM Tracing](/docs/tracing)
    
*   [Prompt Management](/docs/prompts/get-started)
    
*   [Evaluation](/docs/scores/overview)
    
*   [Manual Annotation](/docs/scores/annotation)
    
*   [Datasets](/docs/datasets/overview)
    
*   [Metrics](/docs/analytics)
    
*   [Playground](/docs/playground)
    

Integrations

*   [Python SDK](/docs/sdk/python)
    
*   [JS/TS SDK](/docs/sdk/typescript/guide)
    
*   [OpenAI SDK](/docs/integrations/openai/get-started)
    
*   [Langchain](/docs/integrations/langchain/tracing)
    
*   [Llama-Index](/docs/integrations/llama-index/get-started)
    
*   [Litellm](/docs/integrations/litellm)
    
*   [Dify](/docs/integrations/dify)
    
*   [Flowise](/docs/integrations/flowise)
    
*   [Langflow](/docs/integrations/langflow)
    
*   [Vercel AI SDK](/docs/sdk/typescript/example-vercel-ai)
    
*   [Instructor](/docs/integrations/instructor)
    
*   [Mirascope](/docs/integrations/mirascope)
    
*   [API](https://api.reference.langfuse.com/)
    

Resources

*   [Documentation](/docs)
    
*   [Interactive Demo](/demo)
    
*   [Video demo (3 min)](/video)
    
*   [Changelog](/changelog)
    
*   [Roadmap](/docs/roadmap)
    
*   [Pricing](/pricing)
    
*   [Enterprise](/enterprise)
    
*   [Self-hosting](/docs/deployment/self-host)
    
*   [Open Source](/docs/open-source)
    
*   [Why Langfuse?](/why)
    
*   [Status](https://status.langfuse.com)
    

About

*   [Blog](/blog)
    
*   [Careers](/careers)
    3
*   [About us](/about)
    
*   [Support](/support)
    
*   [Schedule Demo](/schedule-demo)
    
*   [OSS Friends](/oss-friends)
    

Legal

*   [Security](/security)
    
*   [Imprint](/imprint)
    
*   [Terms](/terms)
    
*   [Privacy](/privacy)
    

© 2022-2024 Langfuse GmbH / Finto Technologies Inc.